%%[chapter
\chapter{Results}
\label{cha:results}
In this section we investigate the efficiency of the LLVM backend. We compare the executables generated by LLVM with the executables generated by the C backend using compilation time (\refS{sec:results-compilation-time}), file size (\refS{sec:results-file-size}), execution time (\refS{sec:results-execution-time}), and runtime memory consumption (\refS{sec:results-runtime-memory-consumption}) as comparison criteria. The runtime properties are more important for efficiency than the compile time properties as a program is compiled once but executed many times, but we measure both for completeness.

\section{The measuring environment}
We use 8 simple Haskell programs to evaluate the LLVM backend. The programs used are selected from the nofib~\cite{partain:93} benchmark suite because they are compatible, after minor adjustments, with the limitations of EHC variant 8.

Each of these programs is compiled and executed. File size and runtime memory consumption are only measured once because they are deterministic. Compilation time and execution time are dynamic and so the average 'real time'\footnote{The actual time between the start of the process and the end, including context switches} the time of 50 compilation and execution cycles are measured. 

Our hypothesis is that the conservative garbage collector (\refS{sec:conservative-gc}) is responsible for a large part of the execution time. To verify this claim, we repeat the measurements with executables that exclude the garbage collector library. This does not measure the performance that the end user will experience, but it measures the effect LLVM has on the generated code. Furthermore, it gives insight in the performance gain possible if the conservative collector is replaced by an efficient accurate collector. For the implementation, all calls to the garbage collection allocation functions are replaced by C library \texttt{malloc()} calls and memory is not deallocated during execution. We avoid swapping memory pages by executing the programs on a machine with enough physical memory to hold the memory allocated by the programs.

The benchmarks are performed on a machine with an Intel Core2 processor and 3.2 gigabytes of memory, running 64 bit GNU/Linux with a 2.6.24 kernel. The LLVM files are compiled by LLVM 2.3 with all standard optimizations enabled. The C files are processed by GCC 4.2.3~\cite{gcc:08} with optimization level 2. The produced executables are then stripped, thereby removing the extra bytes of the symbol table.

The implementation and performance of the \texttt{malloc} function differs per platform. In our benchmark environment, we use the \texttt{malloc} implementation supplied by glibc 2.7~\cite{glibc:07}. This implementation, called ptmalloc2~\cite{gloger}, is based on Doug Lea's malloc library~\cite{lea:96}. Although the library is reasonably portable, its performance may vary on different platforms with different configurations. As a result, the numbers used in comparisons between \texttt{malloc} and the garbage collector library can differ for other platforms.

\section{Compile time properties}
We measure two static program properties: compilation time and file size. Compilation time is defined as the time between the invocation of EHC and its successful termination after producing an executable. File size is the size of the executable on disk, including all libraries and prelude functions. The efficiency of the two properties are measured by comparing to the results of the C backend. We consider the LLVM backend to be efficient with respect to a certain property, if the performance is equal with or better than the C backend.

\begin{table}[htbp]
  \begin{center}
  \begin{tabular}{l||rrr||rrr||}
    \input{compiletime.gc}
  \end{tabular}
  \end{center}
  \caption{Compilation time and file size with garbage collection enabled}
  \label{tab:compiletime-gc-data}
\end{table}

\refT{tab:compiletime-gc-data} presents the results of the comparison between the C and LLVM backend for compilation times and file sizes of the produced executables. Each part of the table is divided in another 3 parts: the result for the C backend, the result for the LLVM backend and finally a column labeled 'ratio', the difference ratio between LLVM and the C backend. If the ratio is greater than or equal to 1, LLVM is at least as efficient than the C backend.

\subsection{Compilation time}
\label{sec:results-compilation-time}
For all 8 example programs the compilation time with the LLVM backend is less than the C backend. The ratio varies from 1.22 (\texttt{wheel-sieve2}) to 1.03 (\texttt{tak}). On average, compiling Haskell programs with EHC using C takes 1.11 times the time needed by the LLVM backend. 
The performance gain is explained by the low level of the LLVM assembly language. Parsing and analyzing the assembly language is simpler than parsing and analyzing C code. For example, creating the control flow graph of the program is trivial for LLVM, while this is not the case for the C compiler. The explanation is confirmed when the example programs are analyzed. The relative small programs (\texttt{tak}, \texttt{exp3\_8}) result in a small gain, while the less compact programs (\texttt{wheel-sieve1}, \texttt{wheel-sieve2}) show a higher performance gain.

\subsection{File size}
\label{sec:results-file-size}
The file sizes of the 8 executables produced via LLVM are smaller than when produced via C. On average, the C executables take 1.35 times the size of their LLVM counterparts, which is a significant improvement.

The size reduction is not due to the absence of debug information generation by LLVM. Both the C and LLVM binaries lack debug information and their symbol table is stripped. Instead the gain is obtained by the generation of more compact code and less static data.

\subsection{Effect of the garbage collector}
The executables produced by EHC are statically linked to the libraries that they depend upon. This makes the garbage collector library a possible big part of the compilation time and file size.

\begin{table}[htbp]
  \begin{center}
  \begin{tabular}{l||rrr||rrr||}
    \input{compiletime.nogc}
  \end{tabular}
  \end{center}
  \caption{Compilation time and file size with garbage collection disabled}
  \label{tab:compiletime-nogc-data}
\end{table}

\refT{tab:compiletime-nogc-data} shows the compilation times and file sizes when garbage collection is excluded from the executables. The compilation times with garbage collection disabled are virtually unchanged. We conclude that linking the garbage collection library in the executable costs a negligible amount of time, when compared to the other operations performed.

In contrast with the compilation time, the file size is influenced by the exclusion of the garbage collector. When the garbage collector is disabled, its code is not passed to the linker and excluded from the executable. This results in a file size reduction of approximately 65 kilobytes. For the simple test programs with a limited file size, 65 kilobytes is a big reduction in file size. This is illustrated by the average file size ratio, which increases from 1.35 to 3.23 when garbage collection is disabled. With more elaborate examples, which result in executables of several megabytes, a reduction of 65 kilobytes is not significant.

\section{Runtime properties}
The final two properties that we measure are execution time and runtime memory consumption. Both are only available at runtime. Fast program execution and low runtime memory usage are important for both the programmer and the end user. Programmers benefit from programming languages with high-level abstractions, but these abstractions must result in fairly efficient code. For the end user it is important that the program does not consume a large quantity of resources as other programs require resources too. Both runtime properties are related to each other as large amounts of memory allocations slow the execution down.

The goal of the LLVM backend implementation is to reduce the program execution time significantly compared to the C backend. We use this goal as criteria for its execution time efficiency. We consider the runtime memory consumption property efficient if is comparable to the results of the C backend.

\begin{table}[htbp]
  \begin{center}
  \begin{tabular}{l||rrr||rrr||}
    \input{runtime.gc}
  \end{tabular}
  \end{center}
  \caption{Execution time and runtime memory usage with garbage collection enabled}
  \label{tab:runtime-gc-data}
\end{table}

\refT{tab:runtime-gc-data} presents the results of the comparison between the C and LLVM backend for execution times and runtime memory usages of the produced executables. The structure of the table is similar to the previous tables, with parts for the C backend, the LLVM backend and the ratio.

\subsection{Execution time}
\label{sec:results-execution-time}
\refT{tab:runtime-gc-data} shows the execution time of the 8 test programs. On average executing a program that is compiled via C takes 1.10 times the time needed by the program compiled via LLVM. Such performance gain is very significant for production compilers. EHC is no production quality compiler yet and in terms of optimization still very raw. We feel that the measured increase is a good begin, but that it is not the maximum gain possible.

In contrast to the other measured properties, the execution time for LLVM executables is not always less than C. The test programs \texttt{digits-of-e2} and \texttt{exp3\_8} execute faster when compiled via C, with ratios of 0.81 and 0.93 respectively. On the opposite side of the spectrum are the programs \texttt{tak} and \texttt{queens} which show significant gains with ratios of 1.45 and 1.24 respectively. This raises 3 questions:
\begin{enumerate}
  \item Why does compilation via LLVM result in faster executables on average than compiling via C?
  \item Which properties of the programs \texttt{digits-of-e2} and \texttt{exp3\_8} cause the slower execution when compiled via LLVM?
  \item Which properties of the programs \texttt{tak} and \texttt{queens} are the cause of the significant faster execution when compiled via LLVM?
\end{enumerate}

\subsubsection{LLVM: faster on average}
On average, compilation via LLVM results in faster executables than when the executables are produced via C. We believe that the structure of the C program to support tail calls is a possible cause for this difference.

The C programming language has no native support for tail calls. In order to map tail calls to C, the regular function call and return paradigm must be abandoned and handled explicitly. A Silly function call is translated to a sequence of C statements that store the arguments in a global array and a \texttt{goto} to the address of the function. Returns are implemented by a read of the return address from the global array and a \texttt{goto} to it. The caller is responsible for cleaning up the stack.

The function call mechanism requires two changes to the structure of the C program that, we believe, are an important factor in the performance difference between C and LLVM. The changes are the passing of function parameters via memory and using \texttt{goto} and labels for control flow. 

The function call mechanism transfers all data on the stack, which is located in memory. Many calling conventions pass a number of arguments via registers. This reduces the amount of memory reads and writes, which are expensive compared to register reads and writes. LLVM applies efficient calling conventions which use registers for function parameter transfer. For large amounts of function calls, such as often performed in Haskell executables, this results in a significant reduction of the execution time. 

Additional drawbacks of the function call implementation are the reduced optimization opportunities. By using \texttt{goto} statements with non-constant labels for returns, it is impossible for the compiler to construct a control flow graph of the program. This in contrast to the LLVM program, where the compiler knows the possible return locations. A control flow graph is essential for optimizations as common sub expression elimination and constant propagation.

\subsubsection{LLVM: slower}
\refT{tab:runtime-gc-data} shows 2 test programs which execute faster when compiled via C than via LLVM. For both programs there is a different reason for the degraded performance of the LLVM variant.

The first program is \texttt{exp3\_8}. The program is a small and computes $3^8$ using Peano numbers. The code generated via C executes 0.03 seconds faster than the code generated via LLVM. This absolute difference is small, but the ratio is 0.93 because the execution time is approximately 0.5 seconds. Our initial explanation was the added indirection for the allocations routines (\refF{lst:llvm-gc-file}) that the generated LLVM code uses. The C backend calls the allocation functions directly, while the LLVM backend needs to call a wrapper function. This extra level of indirection is only responsible for a part of the performance reduction. The C compiler simply does a better job than the LLVM compiler when selecting instructions for x86-64. This issue is known by the LLVM developers and a the x86-64 backend is a likely target for improvement in future versions.

The second program, \texttt{digits-of-e2}, has a ratio of 0.81. The execution of the LLVM produced binary takes 1.27 seconds more than the binary generated by the C compiler. This extra execution time is all spend in the garbage collector code. This is remarkable, as both the C and LLVM code allocate the same data and use the same runtime library compiled with the same options. We currently have no explanation for this behaviour. 

\subsubsection{LLVM: significantly faster}
The test suite contains 2 programs which perform significantly faster when compiled with LLVM opposed to C. \texttt{tak} and \texttt{queens}, with a ratio of 1.45 and 1.24 respectively, show a much higher gain than the average. Both programs contain a tail recursive function which is executed often. The LLVM compiler transforms these tail function calls to a loop. The custom function call implementation in the C backend performs tail calls in a similar way but writes the arguments of the functions to memory, as the LLVM backend keeps the arguments in registers. The use of registers significantly speeds up the execution when the tail recursive function is executed often.

\subsection{Runtime memory consumption}
\label{sec:results-runtime-memory-consumption}
Our hypothesis is that the runtime memory usage is not influenced by compilation via LLVM or C. Executables generated via both backends allocate exactly the same closures as the compilers cannot remove calls to allocation functions. The compilers are aware of possible side effects in the allocation function and cannot eliminate the function call without changing the semantics of the program.

The measured data presented in \refT{tab:runtime-gc-data} invalidates the above hypothesis. All 8 example programs use less runtime memory when compiled via LLVM than when compiled via C. The gain is very small, on average consume the executables compiled via C 1.01 times the memory that their LLVM counterparts use. Note that the ratio increases when the program consumes a relative small amount of runtime memory, which suggests a constant difference. Indeed, for all programs is the difference between the C and LLVM column close to 200,100 |GrWord|s. This is caused by the C backend allocating a 200,000 |GrWord| array as its stack and allocating the return node |RP| with a static size of 100 |GrWord|s. The hypothesis of equal runtime memory usage is invalid, but the rationale of it is correct. Both backends create executables that allocate exactly the same closures.

\subsection{Effect of the garbage collector}

\begin{table}[htbp]
  \begin{center}
  \begin{tabular}{l||rrrrr||rrr||}
    \input{runtime.nogc}
  \end{tabular}
  \end{center}
  \caption{Execution time and runtime memory usage with garbage collection disabled}
  \label{tab:runtime-nogc-data}
\end{table}

In order to validate the hypothesis that the garbage collection is responsible for a large part of the execution time, we repeat the measurements with garbage collection disabled. The results of this measurements are shown in \refT{tab:runtime-nogc-data}. In the table, the execution times are suffixed with their ratio to the execution times with garbage collection enabled. A ratio greater than or equal to 1 means that execution without garbage collection is at least as efficient as execution with garbage collection.

This benchmark results shows the influence of the garbage collection library, and shows a clearer comparison between the executables generated via C and LLVM. In this benchmark, the ratio increases from 1.10 to 1.17. Such performance increase by compiling via LLVM instead of via C is a significant increase, even for a raw compiler as EHC. Furthermore the numbers verify the hypothesis about an inefficient garbage collector. On average, with garbage collection is the execution time 1.92 times higher for C and 2.16 times for LLVM. We believe that with an efficient accurate garbage collector, we can approach the 1.17 ratio with garbage collection enabled.

On average, the elimination of garbage collection speeds up the program, but 2 test programs show a performance decrease; \texttt{exp3\_8} and \texttt{tak} need more time for execution when garbage collection is disabled than when it is enabled. This seems strange because without garbage collection, the program just allocates and performs no deallocations. No fragmentation is possible and no time is spend resizing the heap and deallocating structures, so the cause of the slowdown must be in the allocation routines. After investigation, we found that the 2 programs only allocate small structures and the allocation routine of the garbage collector handles this faster than the C library \texttt{malloc()} routine.

Finally, we emphasize the 1.08 ratio of the test program \texttt{digits-of-e2}. With garbage collection enabled, this ratio drops to 0.81. So with garbage collection enabled the C executable is faster, but the LLVM executable is faster when it is disabled. The execution time needed for garbage collection is not always higher for LLVM. The test program \texttt{digits-of-e1} shows that for the LLVM executable the garbage collection takes less time than for the C executable. The other test cases show a nearly equal time for both backends with respect to garbage collection. We have no explanation for this behaviour and suggest further investigation.

\section{Summary}
In the introduction of this thesis, the second research question presented was:
\begin{quote}
\emph{Does the code generated by a Haskell compiler benefit from the optimizations supported by the LLVM framework?}
\end{quote}

In this chapter we investigated 4 properties in order to see if the code generation benefits from the use of LLVM compared to C: compilation time, file size, execution time, and runtime memory usage. The results presented in this chapter show a positive answer on the second research question for the average program. Runtime memory usage improves marginally (ratio 1.01), while compilation time (ratio 1.11), file size (ratio 1.35), and execution time (ratio 1.10) show significant improvements. The gain in execution time is explained by register usage for function calls and loops, instead of the in-memory stack used by the C backend. Also the structure of the C program makes it impossible for the compiler to construct a control flow graph and reduces the options for optimization. Compilation via LLVM is not always faster. The x86-64 backend of LLVM is not as mature as the GCC version, but is a likely target for improvement in future versions.

A large part of the execution time is consumed by the garbage collector. When garbage collection is disabled and data is not deallocated, the ratio of the execution time improves to 1.17. Thus a big improvement in execution speed is possible if the inefficient conservative garbage collector is replaced by an fast accurate garbage collector. The current conservative garbage collector also shows significant difference in execution time for the C backend and the LLVM backend, both allocating exactly the same data. We have no explanation for this behaviour and regard this as future work.
%%]
