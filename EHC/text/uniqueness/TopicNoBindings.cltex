%%[main

\chapter{Lambda-calculus without bindings}
\label{chapt.NoBindings}

In the introduction (Chapter~\ref{chapt.Introduction}) we showed that functional programs perform a lot of copying
in order to preserve referential transparency in the presence of destructive updates. The work in this chapter
makes it possible to get performance similar to that of destructive updates in imperative programs. Two steps are needed to get this
done: the first step is to analyse which values are guaranteed to be used at most once, and the second step
is to insert special code for destructive updates on values that are used at most once. We devote this entire
thesis to the first step, and leave the second step as future work.

This chapter presents a uniqueness type system for a severely restricted language: simply-typed lambda-calculus
with no |let| bindings, but with integers and an addition operator. Although restricted, this languages serves well to
discuss the fundamentals of uniqueness typing, and our implementation of the uniqueness type system. In subsequent
chapters, we extend the language with features, until most of Haskell is covered.

This chapter is organized as follows. We start with an overview of the system and some small examples to give a general
feeling about our approach. Then we provide a rather large example that demonstrates the approach in detail. This example
touches several aspects of our approach, such as the definition of the language, constraint gathering, and constraint
solving. In the remainder of the chapter, we treat these aspects in a more formal fashion.


\section{Intuition}

  We start with an overview of the uniqueness type system. The system consists of two parts. The first part deals with
  constraint generation and the second part deals with constraint solving. This separation is not relevant at this
  point, but is important for separating concerns later in this thesis. The application of an implementation of this
  type system to an expression, we call a uniqueness analysis.

  As we mentioned in the introduction, there are boundaries to what is decidable and what is not. To keep the analysis
  feasible, we associate uniqueness properties with the type of a value and not with the value itself. The analysis is
  conservative: if a type is unique, we know that it is used exactly once, but if it is not, it can be unique but is
  probably not.

  \subsection{Annotations}
  \label{sect.Annotations}

  We consider for a moment what a usage property actually is. During the execution of a program, there are \emph{values} in memory
  and there are \emph{names} bound to values. These names are actually present in memory as \emph{pointers} to a
  value\footnote{Unless the value is unboxed, then the name only exists conceptually.}.
  Consider the program\footnote{The subscripts on |x| are not part of the code, but used as a
  textual disambiguation of the occurrences of |x|.}:

%%[[wrap=code
  (\x -> (\z -> (Sub(z)(3))) (Sub(x)(1)) + (\z -> (Sub(z)(4))) (Sub(x)(2))) 3
%%]

  The names for values are the identifiers and their occurrences: |x|, |(Sub(x)(1))|, |(Sub(x)(2))|, |z|, |(Sub(z)(3))| and |(Sub(z)(4))|. Since
  |(Sub(x)(1))| and |(Sub(x)(2))| are occurrences of |x|, they represent the same value, say |v| (which happens to be 3). The value |v| is exactly
  used once \emph{via} the name |(Sub(x)(1))|. The value |v| is exactly used once via the name |(Sub(x)(2))|. So, in total |v| is used more than
  once via |x|. Thus, |x| represents a value that is used more than once. Because the name |(Sub(x)(1))| represents
  the same value, it also represents a value that is used more than once, even though this value is used only once via |(Sub(x)(1))|. Similarly,
  |(Sub(x)(2))| represents a value that is used more than once. These are two different properties for a name: a property that describes
  the usage of a value via a name, and a property that describes the entire usage of a value represented by a name.

  This concept of names can be generalized to expressions (via referential transparency: an unevaluated expression is a \emph{thunk}, of which
  the memory is later replaced by the actual value). Suppose that |v| is a value represented by an
  expression |E|. An important observation is that there is a difference between a usage property that specifies that |v| is used a number of times
  via |E|, and the property that specifies how often |v| is used in total. An analysis typically focuses on one of these two
  usage properties.

  For uniqueness typing as defined in Clean, only usage properties of values are important. In Clean, a unique type represents a value
  that is used at most once. For each name |x| with a unique type, we know that the corresponding value is used at most once. For example,
  the value represented by |x| is used at most once in |(\x -> const (Sub(x)(5)) (Sub(x)(6))) 3|, but this property does not specify that
  it is used at exactly once via |(Sub(x)(5))| and never through |(Sub(x)(6))|. An optimizer can only assume that if the value is used once via
  the names, that it will not be used via any of the other names. This is sufficient for destructive updates optimisations. Code that
  performs destructive updates can be generated for any operation on a value that is used at most once, because at most one of these operations
  will be performed during a program execution.

  However, there are optimisations that benefit from knowing that a value is used exactly once. A value that is used exactly once, can be
  safely pre-evaluated before passing it to a function. Or a function that is used exactly once, can be inlined safely, always resulting
  into better performing code and a smaller code size. Furthermore, an value that will not be used at all, can be omitted. These are
  realistic and beneficial optimisations, thus for our analysis, we support both types of usage properties.

  We define the \emph{cardinality} property of a type as follows:

%%[[wrap=code
  (Card(Usage)(Usage))
%%]

  The left component defines the usage of some individual name or value. The second component defines the total usage of
  some value. The usage |Usage| is defined as:

%%[[wrap=code
  Usage  ::=  0        -- not used: zero
         |    onemin   -- used at most once: affine, unique
         |    1        -- exactly used once: linear
         |    oneplus  -- used at least once: strict
         |    *        -- arbitrary usage: shared
%%]

  A possible future generalisation of this approach is to support |Usage|-values up to |k > 0|, such that we can specify that some value
  is exactly used |3| times, or at most |10| times. Although this generalisation is fairly straight forward, it is also doubtful
  if there is a use for determining that some value is used at most a certain number of times. Since it only complicates our
  explanation, we stick to the above definition.

  Some optimizations demand that a value is exactly used once, while for other optimizations it is sufficient that a value
  is used at most once, which is slightly less demanding. Our approach can verify both uniqueness properties and
  strictness properties. Although our focus is on uniqueness properties, we consider strictness as well, since we get it
  almost for free with our approach. We still call our approach uniqueness typing, but it is technically more than that.

  A cardinality property is attached to type constructors as \emph{cardinality annotation}. Cardinality originates
  from set theory where it is defined as the number of elements in a set. Some authors use the word cardinality as alternative
  for arity. Our definition of cardinality is unrelated to arity, which is the reason why we stress the difference here.

  Suppose that |x| is a name for value |v| of type |Int|, i.e. |x :: Int| with |memory(x) = v|. To specify that |x|
  uses |v| exactly once via |x|, and that |x| requires that |v| is used exactly once in total, we write:
  |x :: (Sup(Int)(Card(1)(1)))|. To specify that |x| does not use |v| via |x|, and that |x| requires |v| to be
  used exactly once in total, we write: |x :: (Sup(Int)(Card(0)(1)))|. Similarly, suppose that |f| is the name for a closure |cl|,
  i.e. a function |f :: Int -> Int|. Then |f :: (Sup(Int)(Card(1)(*))) (Sup(->)(Card(1)(1))) (Sup(Int)(Card(1)(*)))| specifies that
  |f| uses |cl| exactly once via |f|, and that |f| requires that |cl| is used exactly once in total. Furthermore,
  the annotated type specifies that for an argument-value |a|, |f| provides that it uses |a| exactly once, and makes no
  demands about the total usage of |a|. Finally, the annotated type specifies that for a result-value |r|, |f| requires that |r| is
  used exactly once, and gives no guarantees about the total usage of |r|.

  The analysis expects a program annotated in this fashion and verifies that the annotations are correct (inference in
  Chapter~\ref{chapt.Polyvariant}). Unfortunately, we cannot easily formulate the conditions of when an annotation is
  correct or not. We have to check two things: does the annotation fit with related annotations (the context), and
  does the annotation fit with the actual uses of the value. With context we mean that if two types are unified,
  that their annotations also unify. For example, a value with cardinality |(Card(1)(1))| cannot be passed to a function that
  has |(Card(onemin)(1))| cardinality for its parameter, because the function does not guarantee that the value will always be used.
  With the actual uses of the value, we mean the guaranteed upper and lower bound on the number of times the value will be evaluated
  or referenced. For example, a value that is referenced at least once cannot have the cardinality annotation |(Card(0)(0))|. We have
  sufficient information for the context check (which is basically a form of unification, and checks the right-hand side of the cardinality annotation), but insufficient information for the
  check on the usages (the left-hand side of the cardinality annotation).

  We therefore ask the programmer to specify an upper and lower bound on the type of an expression (or name). The types in an expression are
  thus annotated with three (!) annotations: A cardinality annotation, a lower-bound usage-count annotation, and an upper-bound usage-count annotation.
  The lower-bound usage-count annotation tells us that a value is at
  least used a certain number of times via the expression, and the upper-bound usage-count annotation tells us that a value is at most
  used a certain number of times via the expression. The usage-check demands that left-hand side of the cardinality annotation \emph{fits} within these
  bounds (Figure~\ref{code.FitsInBounds}). The upper and lower bound can be verified by means of an analysis, which in turn
  means that we can verify the cardinality annotations.

  We explain by means of an example how these three annotations interact and how we formulate the checks as
  a constraint satisfaction problem. Unfortunately, that is rather hard to grasp at this point, so we defer
  the explanation to Section~\ref{sect.BigExample}. Instead, we discuss how to check the upper-bound
  usage-count annotations here, since the checks on the lower-bound usage-count and also the context-check on the
  usage annotations themselves are quite similar. This will become clear in Section~\ref{sect.BigExample}.

  \subsection{Checking the upper-bound usage-count annotation}

  An upper-bound usage-count annotation |u| specifies that the corresponding values are used at most |u| times:

%%[[wrap=code
  UpperBound  ::=  0            -- Not used.
              |    1            -- Used at most once.
              |    *            -- Arbitrary usage. However, typically represents a number greater than one.
%%]

  We assume that expressions are annotated with upper-bound usage-count annotations. That means that
  all type constructors occurring in the types of an expression have an upper-bound usage-count annotation.
  For example, an annotated version of the expression |(\x -> x) 3| is\footnote{Again, note that the subscripts are not part of the code. They are used in the text to refer to a particular type.}:

%%[[wrap=code
  (\x -> x) 3  -- original expression
  (((\(x :: Int) -> x :: Int) :: Int -> Int) (3 :: Int)) :: Int  -- typed expression
  (((\(x :: (Sup(Sub(Int)(a))(1))) -> x :: (Sup(Sub(Int)(b))(1))) :: (Sup(Sub(Int)(c))(1)) (Sup(Sub(->)(d))(1)) (Sup(Sub(Int)(e))(1))) (3 :: (Sup(Sub(Int)(f))(1)))) :: (Sup(Sub(Int)(g))(1))  -- typed expression with annotations
%%]

  This looks quite intimidating, but let us consider what is displayed here. The outermost expression is annotated
  with |(Sup(Sub(Int)(g))(1))|, which means that the result of the expression is used at most once. The outermost expression
  is an application of an argument to a function. The annotated type of the function is |(Sup(Sub(Int)(c))(1)) (Sup(Sub(->)(d))(1)) (Sup(Sub(Int)(e))(1))|. The annotation on the
  arrow type constructor, |(Sup((Sub(->)(d)))(1))|, specifies that the function is used at most once. The annotation
  |(Sup(Sub(Int)(c))(1))| specifies that the parameter is used at most once, and |(Sup(Sub(Int)(e))(1))| demands
  that the result is used at most once. The annotation |(Sup(Sub(Int)(f))(1))| specifies that the argument
  is used at most once. The annotation on the parameter of the function and the annotation on the argument of the
  function are related to each other. Likewise, the annotation on the result of the function is related to the
  annotation on the function application. The annotation of the parameter of the function is related to the
  annotation of the result of the function, but that depends on the structure of the body of the function.
  Take a moment to get a clear picture of the annotations and their meaning.

  Are these annotations correct? For this example, it is not difficult to see that indeed the value |3| is not used
  more than once, but we need a systematic approach to verify this. We check the annotations by a traversal over the
  structure of the expression, and approximate the upper bound from below. By computing an approximation of a least
  upper bound, we check that the upper bound provided by the programmer is high enough to be an upper bound for any
  execution of the program. In other words, we determine from the structure of the program that the upper bound
  should be at least |m| to be an upper bound, and verify that the upper bound given by the programmer is at least
  |m|. The upper bound is allowed to be higher than is strictly necessary (safe approximation).

  The root of the expression is the starting point. When executing the expression, the root
  is evaluated once to obtain the value. So, the upper bound for the root of the expression is at least |1|. The annotated
  type of the root, |(Sup(Int)(1))|, is therefore correct. The root of the expression is a function application. Since the
  annotation is correct, it means that the upper bound for the function application is at least the upper bound of the
  root of the expression, thus at least |1|. The function is used at least as often as the function application, so
  the upper bound of the function is at least the upper bound of the function application, thus at least |1|. The annotation
  on |(Sup(Sub(->)(d))(1))| is correct. The same reasoning applies to the result of the function. The upper bound of the result
  of the function is at least the upper bound of the function application. The annotation on |(Sup(Sub(Int)(e))(1))| is correct.

  Now the function and the argument. Consider the argument first. The function fully determines how often it
  is used. The upper bound of the argument is at least the upper bound of the parameter of the function. The annotation
  on |(Sup(Sub(Int)(c))(1))| is the upper bound of the parameter, thus the upper bound of the argument is at least
  |1|. |(Sup(Sub(Int)(f))(1))| is correct. Of course, we have to verify that the upper bound of the parameter of the
  function is |1|. We take a look at the function. The body of the function has an upper bound of |1|, because the result
  of the function has an upper bound of |1|. The body of the function is a use of parameter |x|. So, the upper bound for
  this occurrence of |x| is |1|. The annotation on |(Sup(Sub(Int)(b))(1))| is correct. The upper bound for the parameter
  |x| is at least the sum of the upper bounds of the occurrences. There are no other occurrences of |x|,
  so the aggregated upper bound of |x| is |1|. We come back to this specific subject later. The annotation on
  |(Sup(Sub(Int)(a))(1))| is correct. Again, take a moment
  to get a mental picture of how the abstract syntax tree is traversed and how annotations are compared from outermost
  expressions to innermost expressions and from left to right.

  An important step is the aggregation of upper bounds for occurrences of an identifier. The following variation of
  the above example shows why it is important:

%%[[wrap=code
  (\x -> x + x) 3  -- original expression
  (((\(x :: Int) -> ((x :: Int) + (x :: Int)) :: Int) :: Int -> Int) (3 :: Int)) :: Int  -- typed expression
  (\((Sub(x)(0)) :: (Sup(Sub(Int)(a))(*))) -> ((Sub(x)(1)) :: (Sup(Sub(Int)(b))(1))) + ((Sub(x)(2)) :: (Sup(Sub(Int)(c))(1)))) (3 :: (Sup(Sub(Int)(d))(*)))  -- typed expression with annotations
%%]

  The number of times a value bound to |(Sub(x)(0))| is used, is the aggregated number of times the value is used as |(Sub(x)(1))| and
  |(Sub(x)(2))|. Any actual usage count for |(Sub(x)(1))| or |(Sub(x)(2))| is lower than their corresponding upper bound. A safe approximation for
  a least upper bound of |(Sub(x)(0))| is the sum of the upper bounds of |(Sub(x)(1))| and |(Sub(x)(2))|. As the example shows, the upper
  bounds of |(Sub(x)(1))| and |(Sub(x)(2))| are both |1|, so the sum is |*| and the annotation is correct.

  As we mentioned several times already, a conservative approximation of the upper bound is allowed. The upper bound may
  be higher than is strictly necessary. For example, if we know that a value is not used, we may also assume that
  it is at most used once. Furthermore, assuming that some value is used an arbitrary number of times is always allowed. It
  is safe to pretend that the upper bound is higher than is actually the case, but it makes the analysis result less accurate.

  The following example is a variation upon the earlier example where some of the annotations are higher than
  is strictly necessary:

%%[[wrap=code
  (\x -> x) 3  -- original expression
  (((\(x :: Int) -> x :: Int) :: Int -> Int) (3 :: Int)) :: Int  -- typed expression
  (((\(x :: (Sup(Sub(Int)(a))(*))) -> x :: (Sup(Sub(Int)(b))(1))) :: (Sup(Sub(Int)(c))(*)) (Sup(Sub(->)(d))(*)) (Sup(Sub(Int)(e))(1))) (3 :: (Sup(Sub(Int)(f))(*)))) :: (Sup(Sub(Int)(g))(1))
%%]

  We verify again that these annotations are correct. The value of the outermost expression is used at most once, so
  the upper bound is at least |1|. The annotation on |(Sup(Sub(Int)(g))(1))| is correct. The upper bound for
  the function itself is at least as high as the upper bound for the function application. The upper bound
  for the function is |*|, which is at least as high as the upper bound of |1| of the function application.
  The annotation on |(Sup(Sub(->)(d))(*))| is correct. The result of the function has an upper bound of |1|,
  which is at least as high as the upper bound of |1| of the function application. The annotation on
  |(Sup((Sub(Int)(e)))(1))| is correct. The aggregated upper bound for |x| is at least the sum of the upper bounds of
  the occurrences of |x|, which in this case is |(Sup(Sub(Int)(b))(1))|. The annotation on
  |(Sup(Sub(Int)(a))(*))| is higher, but that is allowed, so it is correct. Consequently, our traversal of the
  expression demands that the annotations on |(Sup(Sub(Int)(c))(*))| and |(Sup(Sub(Int)(f))(*))| are at
  least the annotation on |(Sup(Sub(Int)(a))(*))|, which is correct.

  To summarize: what our analysis does is to start with some known information about the root of the expression
  and `push' it through the abstract syntax tree from outermost to innermost, and in case of functions from result to
  arguments based on the body. A mental picture is that there is an `flow' of count-information from the
  root of the expression to the leaves. We say that the analysis 'propagates' counts. We see in later sections that
  dealing with a lower bound, and dealing with cardinality annotations, is not much different than what we did in
  this section.

\section{The next step}
\label{sect.BigExample}

  With the intuitions gained in the previous section, we introduce a constraint-based approach to uniqueness
  typing. For example, for the upper bound analysis of the previous section, we generate a constraint
  |... =>= ...| for each time we wrote `at least', and a constraint |... \*/ ... \*/ ... <= ...| where
  we aggregated upper bounds. It that it? Yes, that is it basically, because we will show that the
  same constraints can be used for the lower bound analysis and the analysis for the actual cardinality
  values.

  The running example in this section is the following expression:

%%[[wrap=code
  (\x y -> (y + x) + x) 3 4
%%]

  The result of this program is evaluated once when the program is executed. Consequently, the results of
  both additions are used once, and thus is the |x| parameter used twice and the |y| parameter once. Which
  in turn means that the value |3| is used twice and the value |4| once. In terms of usage, the
  value |3| is linear (exactly once), and the value |4| is strict (more than once).

  Efficient code can be produced with this usage information. A conventional implementation of addition in a pure,
  lazy language, evaluates both arguments, allocate memory for an integer, and store the result of
  the addition there. But in this case, there is no need to allocate memory for the result of the additions.
  Since the value passed to |y| is linear, the value of |x| can be added directly to the value of |y|
  (destructively updating the value of |y|). The result of the addition is again linear, and the
  value of |x| can be added directly again for the second addition. The result: less memory allocation,
  less copying, and better cache utilization. If the compiler also inlines functions that are at most
  used once, and evaluates strict values before passing it to a function, then we believe that this code is
  as efficient as the imperative program:

%%[[wrap=code
  int y;
  y = 4;
  y += 3;
  y += 3;
  return y;
%%]

  \subsection{Annotations}

  Usage information is encoded as a cardinality annotation on the type constructors in the type of a value.
  The type constructors specify how a value is represented in memory. For example, the value 3 is represented
  as a sequence of 32 bits somewhere in memory. The type constructor |Int| of the type of the value 3,
  corresponds with this area of memory. The cardinality annotation determines the cardinality properties of the
  area of memory. Likewise, the function type constructor |(->)| corresponds to a closure, which is an area
  of memory which contains a pointer to the code of the function, and pointers to values where the
  function depends on, among other information~\cite{wray89nonstrict}. The exact contents of the closure does
  not matter for our explanation. Just assume that it represents the bookkeeping required for applying the
  function to some value. The cardinality annotation on the function type constructor specifies the cardinality
  property of this closure. To know the cardinality of a memory area (part of a value), lookup the annotation on
  the type constructor that corresponds to the area of memory (Section~\ref{sect.TpAnnConstr}).

  As mentioned in the introduction, a type has three annotations. This looks horrible, but fortunately, we can
  do something against it the next chapter. As an example of a triple of annotations, consider the type |(Sup(Int)((1,(Card(oneplus)(oneplus)),*)))|. The first
  annotation is the lower-bound usage-count annotation, which specifies that the value is used at least once.
  The second annotation is the cardinality annotation, specifying that the value is strict, meaning that it is used
  one or more times. The third annotation is the upper-bound usage-count annotation, which specifies
  that the value is at most used an arbitrary number of times. This triple is consistent if the cardinality annotation
  fits the two bounds (Figure~\ref{code.FitsInBounds}) and the left-hand side of the cardinality annotation does not conflict with the right-hand side
  of the cardinality annotation (Section~\ref{sect.TpAnnConstr}).

  For the above example, a possible annotation is:

%%[[wrap=code
    (  (  (  \(x :: (Sup(Int)((1, (Card(1)(oneplus)), *)))) ->
               \(y :: (Sup(Int)((1, (Card(1)(1)), *)))) ->
                 (  (  y :: (Sup(Int)((1, (Card(1)(1)), 1)))
                    +  x :: (Sup(Int)((1, (Card(1)(oneplus)), *)))
                    ) :: (Sup(Int)((1, (Card(1)(1)), 1))))
                 +  x :: (Sup(Int)((1, (Card(1)(oneplus)), *)))
                 ) :: (Sup(Int)((1, (Card(1)(1)), 1)))
          ) :: (Sup(Int)((1, (Card(1)(oneplus)), *))) (Sup(->)((1, (Card(1)(1)), 1))) (Sup(Int)((1, (Card(1)(1)), 1))) (Sup(->)((1, (Card(1)(1)), 1))) (Sup(Int)((1, (Card(1)(1)), 1))))
          (3 :: (Sup(Int)((1, (Card(1)(oneplus)), *))))
       ) :: (Sup(Int)((1, (Card(1)(1)), 1))) (Sup(->)((1, (Card(1)(1)), 1))) (Sup(Int)((1, (Card(1)(1)), 1))))
       (4 :: (Sup(Int)((1, (Card(1)(1)), 1))))
    ) :: (Sup(Int)((1, (Card(1)(1)), 1)))
%%]

  This looks quite intimidating, but that is just because there are a lot of types involved and the
  annotations take much space. In the next chapter, we infer all annotations, and the lower
  and upper bound annotations become implicit, resulting in cleaner types (Section~\ref{sect.TheInferencer}).
  But we first have to do the dirty work here.

  \subsection{Checking the annotations}

  How to check that the annotated typing of a program is valid? First we check that the program is correctly
  typed for the conventional type system of simply typed lambda-calculus. Secondly, we check that all
  triples of annotations are consistent. Then it is time for the real work:
  gather a set of constraints from the annotated program, and check if the constraints are satisfied. When the
  constraints are satisfied, the annotations are correct and the program is correctly typed according to the
  uniqueness type system.

  As an aside, in order to keep the explanation compact, we are a bit
  sloppy in distinguishing identifiers, values and types. For example, if we talk about the upper bound of
  a function, we intend the upper-bound usage-count annotation on the type constructor associated with the
  value representing the function. Or when we talk about the cardinality of an expression, we actually mean how
  often the value corresponding to the expression is used. So, assume that the notion of obtaining a cardinality annotation, upper bound,
  and lower bound is overloaded for identifiers, expressions, values, types and type constructors in the obvious way.

  We illustrate the constraints by analyzing the example\footnote{For clarity, the annotations values have a number
  superscripted to show where they appear in the constraints.}. For a description of the constraints and their
  meaning, check Section~\ref{sect.TpAnnConstr}. We reason about a program in an outermost-to-innermost way. We
  start with the entire program (expression):

%%[[wrap=code
    ( ... ) :: (Sup(Int)(((Sup(1)(1)), (SCard(1)(2)(1)), (Sup(1)(3)))))
%%]

  The result of the entire expression is exactly used once. However, we are allowed to be less accurate for the result
  of the entire expression. Any usage value that is consistent is allowed. We generate the constraint |(1, (Card(1)(*)), 1) (Sub(=>=)(s)) ((Sup(1)(1)), (SCard(1)(2)(1)), (Sup(1)(3)))|. This constraint specifies that the lower bound
  is at most |1|, the upper bound is at least |1|, and the cardinality annotation can be anything as long as it is consistent with
  the two bounds in the triple. The subscript |s| indicates that the cardinality annotation is ignored in this
  constraint. A |=>=| constraint without the |s| suffix is encountered later in the example. The generated constraint expresses what
  we know about the result of the entire expression. We call this constraint a flow or propagation constraint, because with some
  imagination, it `pushes' values on the left-hand side to the right-hand side. We often call a |=>=| constraint a coercion, which
  is explained in the next section.

  One step into the expression, an application is encountered:

%%[[wrap=code
    (( ... :: (Sup(Int)(((Sup(1)(4)), (SCard(1)(5)(1)), (Sup(1)(6))))) (Sup(->)(((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9))))) (Sup(Int)(((Sup(1)(10)), (SCard(1)(11)(1)), (Sup(1)(12)))))) (4 :: (Sup(Int)(((Sup(1)(13)), (SCard(1)(14)(1)), (Sup(1)(15))))))) :: (Sup(Int)(((Sup(1)(16)), (SCard(1)(17)(1)), (Sup(1)(18)))))
%%]

  Several constraints are generated for a function application:

  \begin{itemize}
  \item The function application and the function. The number of usages of the function depends on the number of usages of the
        function application. We generate the constraint |((Sup(1)(16)), (SCard(1)(17)(1)), (Sup(1)(18))) (Sub(=>=)(s)) ((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9)))|.
        The lower bound of the function (|(Sup(1)(7))|) is at most the lower bound of the function application (|(Sup(1)(16))|). The upper bound of
        the function (|(Sup(1)(18))|) is at least the upper bound of the function application (|(Sup(1)(9))|). The constraint
        expresses precisely how often the function is used, if we know how often the function application itself is used.
        The cardinality annotations are unrelated, since the memory occupied by the closure (function) is unrelated to the memory
        occupied by the result of the function.
  \item The function application and result of the function. The number of uses of the result of the function application depends on
        how often the function application itself is used. We generate the constraint |((Sup(1)(16)), (SCard(1)(17)(1)), (Sup(1)(18))) =>= ((Sup(1)(10)), (SCard(1)(11)(1)), (Sup(1)(12)))|.
        The lower bound of the result of the function (|(Sup(1)(10))|) is at most the lower bound of the function application (|(Sup(1)(16))|). The upper bound of
        the result of the function (|(Sup(1)(18))|) is at least the upper bound of the function application (|(Sup(1)(12))|). The cardinality annotation (|(SCard(1)(11)(1))|)
        of the result of the function should be equal (modulo coercion/weakening) to the cardinality annotation of the function application (|(SCard(1)(17)(1))|), since they
        represent the same value (via referential transparency).
  \item The function and the argument of the function application. The uses of the argument of the function
        application depend on the annotations of the parameter of the function. We generate the constraint |((Sup(1)(4)), (SCard(1)(5)(1)), (Sup(1)(6))) =>= ((Sup(1)(13)), (SCard(1)(14)(1)), (Sup(1)(15)))|.
        The semantics of the constraint capture the relations between the three annotations on the type of the function parameter and
        the type of the argument value.
  \end{itemize}

  The remainder of the constraints are obtained by analysing the function expression and the argument expression. There is no constraint generated for
  the argument expression, since that is an |Int| expression, and each consistent triple is valid. In other words: the value |3| can
  represent a linear |Int|, but also a strict |Int| or an affine |Int|. So, verifying the function expression is what remains.

  The function expression is again an application:

%%[[wrap=code
    ( ... :: (Sup(Int)(((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21))))) (Sup(->)(((Sup(1)(22)), (SCard(1)(23)(1)), (Sup(1)(24))))) ((Sup(Int)(((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27))))) (Sup(->)(((Sup(1)(28)), (SCard(1)(29)(1)), (Sup(1)(30))))) (Sup(Int)(((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))))))
      (3 :: (Sup(Int)(((Sup(1)(34)), (SCard(oneplus)(35)(oneplus)), (Sup(*)(36))))))
        :: (Sup(Int)(((Sup(1)(4)), (SCard(1)(5)(1)), (Sup(1)(6))))) (Sup(->)(((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9))))) (Sup(Int)(((Sup(1)(10)), (SCard(1)(11)(1)), (Sup(1)(12)))))
%%]

  This is basically the same situation as above, except with one important difference. The type of the result of the
  function application is a function. Its type has more than one type constructor, and multiple triples of annotations.
  Each type constructor in one type has a corresponding type constructor in the other type. The |=>=| constraint is generated
  between triples attached on corresponding type constructors. This way we check annotations that represent the same values. The direction of the |=>=| constraint depends on co-variance and contra-variance. The
  direction is reversed for |=>=| constraints between \emph{contra-variant} type constructors. The reason is that a co-variant type
  constructor corresponds to values for which the annotation requires some property (``I must be used exactly once''), whereas
  contra-variant type constructors correspond to values for which the annotations provide some property (``I am used exactly once''),
  which is essentially the inverse direction. See Peyton Jones~\cite{peytonjones04pract-inf-rank} for an elaborate explanation
  on co-variance, contra-variance, and subtyping.

  Applying the same reasoning as with the previous function application, we generate the following constraints:

%%[[wrap=code

    ((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9)))                 (Sub(=>=)(s))  ((Sup(1)(22)), (SCard(1)(23)(1)), (Sup(1)(24)))              -- use of the function
    ((Sup(1)(10)), (SCard(1)(11)(1)), (Sup(1)(12)))              =>=            ((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))              -- use of the function value (resulting Int, co-variant)
    ((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9)))                 =>=            ((Sup(1)(28)), (SCard(1)(29)(1)), (Sup(1)(30)))              -- use of the function value (function type, co-variant)
    ((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27)))              =>=            ((Sup(1)(4)),  (SCard(1)(5)(1)), (Sup(1)(6)))                -- use of the function value (argument Int, contra-variant)
    ((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21)))  =>=            ((Sup(1)(34)), (SCard(oneplus)(35)(oneplus)), (Sup(*)(36)))  -- use of the argument
%%]

  Yet to analyse are the function of the function application, and the argument of the function application. The argument
  is again an |Int| expression, which does not result in constraints, so we proceed with the function expression.

  The function expression is a lambda abstraction:

%%[[wrap=code
    ( \(x :: (Sup(Int)(((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21)))))) (y :: (Sup(Int)(((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27)))))) -> ... y :: (Sup(Int)(((Sup(1)(37)), (SCard(1)(38)(1)), (Sup(1)(39))))) ... (Sub(x)(1)) :: (Sup(Int)(((Sup(1)(40)), (SCard(1)(41)(oneplus)), (Sup(*)(42))))) ... (Sub(x)(2)) :: (Sup(Int)(((Sup(1)(43)), (SCard(1)(44)(oneplus)), (Sup(*)(45)))))
    ) :: (Sup(Int)(((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21))))) (Sup(->)(((Sup(1)(22)), (SCard(1)(23)(1)), (Sup(1)(24))))) ((Sup(Int)(((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27))))) (Sup(->)(((Sup(1)(28)), (SCard(1)(29)(1)), (Sup(1)(30))))) (Sup(Int)(((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33))))))
%%]

  For a lambda abstraction, we perform two tasks: analyze the body of the lambda abstraction, and
  combine the results of the uses of the values represented by the parameters. The bounds of each
  occurrence of some parameter are individually established. We generate an aggregation constraint
  to combine the bounds and to check that the cardinality value is properly split over the
  occurrences: |triple((Sub(use_site)(1))) \*/ ... \*/ triple((Sub(use_site)(n))) <= triple(def_site)|.
  We use the safe approximation that the upper bounds are combined by addition and the lower bounds
  by taking the minimum. This approach is improved in Chapter~\ref{chapt.Parallel}.
  This constraint ensures that we check that the lower-bound is low enough and the upper-bound is high enough. Furthermore,
  the constraint ensures that if the parameter has some cardinality value |u|, then the combined
  occurrences correspond to |u|. For example, if |u| is linear, it means that one of the occurrences must be linear and
  all the other occurrences not used.

  With only one use-site of |y|, and two use-sites of |x|, the constraints are:

%%[[wrap=code
   ((Sup(1)(40)), (SCard(1)(41)(oneplus)), (Sup(*)(42))) \*/ ((Sup(1)(43)), (SCard(1)(44)(oneplus)), (Sup(*)(45))) <= ((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21)))  -- for x
   ((Sup(1)(37)), (SCard(1)(38)(1)), (Sup(1)(39))) <= ((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27)))                                                                              -- for y
%%]

  The function body remains to be checked. The function body consists of the additions:

%%[[wrap=code
  ((y :: (Sup(Int)(((Sup(1)(37)), (SCard(1)(38)(1)), (Sup(1)(39)))))) + ((Sub(x)(1)) :: (Sup(Int)(((Sup(1)(40)), (SCard(oneplus)(41)(oneplus)), (Sup(*)(42))))))) :: (Sup(Int)(((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))))
  ((( ... ) :: (Sup(Int)(((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))))) + ((Sub(x)(2)) :: (Sup(Int)(((Sup(1)(43)), (SCard(oneplus)(44)(oneplus)), (Sup(*)(45))))))) :: (Sup(Int)(((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33))))))
%%]

  The addition operator uses both the arguments at least as many times as the result is used. The default operational
  semantics for addition stores the result of the addition in a memory location unrelated to the arguments of the
  addition. So, cardinality annotations of the arguments of the addition are unrelated to the cardinality annotation on the result
  of the addition. But the lower-bound and upper-bound annotations of the arguments are related to the lower-bound and
  upper-bound annotations of the result of the expression. The cardinality annotation on the result of the addition may be
  any value that fits the two bounds. For the relation between the arguments of the addition and the result of the
  addition, we generate a weaker version of the |=>=| constraint that ignores the cardinality annotation, but does not
  ignore the two bounds: |(Sub(=>=)(s))|, with the |s| of \emph{soft}. When we want to stress the difference between these
  two |=>=| constraints, we write the normal |=>=| constraint as |(Sub(=>=)(h))|, with the |h| of \emph{hard}.

  The following constraints relate the result of the additions properly to the arguments of the addition:

%%[[wrap=code
    ((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))  (Sub(=>=)(s))  ((Sup(1)(37)), (SCard(1)(38)(1)), (Sup(1)(39)))
    ((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))  (Sub(=>=)(s))  ((Sup(1)(40)), (SCard(1)(41)(oneplus)), (Sup(*)(42)))
    ((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))  (Sub(=>=)(s))  ((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))
    ((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))  (Sub(=>=)(s))  ((Sup(1)(43)), (SCard(1)(44)(oneplus)), (Sup(*)(45)))
%%]

  \subsection{Checking the constraints}

  The final part of this example is to verify that the constraints hold. We show by an example how we interpret
  the constraints. We define when a constraint holds more precisely in Section~\ref{Sect.CheckingConstraints}. We assume that
  the triples are already checked for consistency, meaning that the cardinality annotation fits between the upper and
  lower bound, and that the cardinality annotation itself is consistent. A cardinality annotation is consistent if the
  left-hand side does not conflict with the right-hand side. The table in Figure~\ref{tab.con} lists the constraints and their
  interpretation (see Figure~\ref{splitFunc} for the definition of |isSplit|).

  
  \begin{PlainFigure}{}{Constraint interpretation}{tab.con}
  \begin{tabular}{llllr}
    constraint & lower bound & usage & upper bound \\
    \hline
      |(1, *, 1) (Sub(=>=)(s)) ((Sup(1)(1)), (SCard(1)(2)(1)), (Sup(1)(3)))|   & |1 leqL (Sup(1)(1))| & & |1 <= (Sup(1)(3))|  \\
      |((Sup(1)(16)), (SCard(1)(17)(1)), (Sup(1)(18))) (Sub(=>=)(s)) ((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9)))| & |(Sup(1)(16)) leqL (Sup(1)(7))| & & |(Sup(1)(18)) leqU (Sup(1)(9))| \\
      |((Sup(1)(16)), (SCard(1)(17)(1)), (Sup(1)(18))) =>= ((Sup(1)(10)), (SCard(1)(11)(1)), (Sup(1)(12)))|  & |(Sup(1)(16)) leqL (Sup(1)(10))| & |(SCard(1)(17)(1)) leqC (SCard(1)(11)(1))| & |(Sup(1)(18)) leqU (Sup(1)(12))|  \\
      |((Sup(1)(4)), (SCard(1)(5)(1)), (Sup(1)(6))) =>= ((Sup(1)(13)), (SCard(1)(14)(1)), (Sup(1)(15)))|       & |(Sup(1)(4)) leqL (Sup(1)(13))| & |(SCard(1)(5)(1)) leqC (SCard(1)(14)(1))| & |(Sup(1)(6)) leqU (Sup(1)(15))| \\
      |((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9)))      (Sub(=>=)(s))  ((Sup(1)(22)), (SCard(1)(23)(1)), (Sup(1)(24)))|    & |(Sup(1)(7)) leqL (Sup(1)(22))| &  & |(Sup(1)(9)) leqU (Sup(1)(24))|  \\
      |((Sup(1)(10)), (SCard(1)(11)(1)), (Sup(1)(12)))   =>=  ((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))|    & |(Sup(1)(10)) leqL (Sup(1)(31))| & |(SCard(1)(11)(1)) leqC (SCard(1)(32)(1))| & |(Sup(1)(12)) leqU (Sup(1)(33))| \\
      |((Sup(1)(7)), (SCard(1)(8)(1)), (Sup(1)(9)))      =>=  ((Sup(1)(28)), (SCard(1)(29)(1)), (Sup(1)(30)))|    & |(Sup(1)(7)) leqL (Sup(1)(28))| & |(SCard(1)(8)(1)) leqC (SCard(1)(29)(1))| & |(Sup(1)(9)) leqU (Sup(1)(30))| \\
      |((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27)))   =>=  ((Sup(1)(4)), (SCard(1)(5)(1)), (Sup(1)(6)))|    & |(Sup(1)(25)) leqL (Sup(1)(4))| & |(SCard(1)(26)(1)) leqC (SCard(1)(5)(1))| & |(Sup(1)(27)) leqU (Sup(1)(6))| \\
      |((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21)))  =>=  ((Sup(1)(34)), (SCard(oneplus)(35)(oneplus)), (Sup(*)(36)))|    & |(Sup(1)(19)) leqL (Sup(1)(34))| & |(SCard(oneplus)(20)(oneplus)) leqC (SCard(oneplus)(35)(oneplus))| & |(Sup(*)(20)) leqU (Sup(*)(36))| \\
      |((Sup(1)(40)), (SCard(1)(41)(oneplus)), (Sup(*)(42))) \*/ ((Sup(1)(43)), (SCard(1)(44)(oneplus)), (Sup(*)(45)))| & |(Sup(1)(40)) `max` (Sup(1)(43))| & |{(Sub(1)(41)), (Sub(1)(44))} `isSplit` (Sub(oneplus)(20))|  & |(Sup(1)(42)) + (Sup(1)(45))| \\
      |^^^ <= ((Sup(1)(19)), (SCard(oneplus)(20)(oneplus)), (Sup(*)(21)))| & |^^^ leqL (Sup(1)(19))| & |&& (Sub(oneplus)(20)) === (Sub(oneplus)(20)) === (Sub(oneplus)(20)))| & |^^^ leqU (Sup(1)(21))| \\
      |((Sup(1)(37)), (SCard(1)(38)(1)), (Sup(1)(39))) <= ((Sup(1)(25)), (SCard(1)(26)(1)), (Sup(1)(27)))|  & |(Sup(1)(37)) leqL (Sup(1)(25))| & |{(Sub(1)(38))} `isSplit` (Sub(1)(26)) && (Sub(1)(38)) === (Sub(1)(26))| & |(Sup(1)(39)) leqU (Sup(1)(27))| \\
      |((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))  (Sub(=>=)(s))  ((Sup(1)(37)), (SCard(1)(38)(1)), (Sup(1)(39)))|  & |(Sup(1)(46)) leqL (Sup(1)(37))| &  & |(Sup(1)(48)) leqU (Sup(1)(39))| \\
      |((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))  (Sub(=>=)(s))  ((Sup(1)(40)), (SCard(1)(41)(oneplus)), (Sup(*)(42)))|  & |(Sup(1)(46)) leqC (Sup(1)(40))| &  & |(Sup(1)(48)) leqU (Sup(*)(42))| \\
      |((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))  (Sub(=>=)(s))  ((Sup(1)(46)), (SCard(1)(47)(1)), (Sup(1)(48)))|  & |(Sup(1)(31)) leqL (Sup(1)(46))| &  & |(Sup(1)(33)) leqU (Sup(1)(48))| \\
      |((Sup(1)(31)), (SCard(1)(32)(1)), (Sup(1)(33)))  (Sub(=>=)(s))  ((Sup(1)(43)), (SCard(1)(44)(oneplus)), (Sup(*)(45)))|  & |(Sup(1)(13)) leqL (Sup(1)(43))| & & |(Sup(1)(33)) leqU (Sup(*)(45))| \\
  \end{tabular}
  \end{PlainFigure}

  The relation |leqL| should be interpreted as the relation |>=| on natural numbers. The relation |leqU| as |<=| on natural numbers. The |leqC|
  relation is somewhat complicated. For the left component in the cardinality annotation, the |leqC| relation specifies 'is more specific',
  and for the right component the relation is equality modulo coercion. We cover these relations in more detail in Section~\ref{sect.TpAnnConstr}.

  All constraints are satisfied, so the program was properly annotated. But this is only one of the annotations for this program that satisfy the
  above constraints. For example, take |0| for all lower bounds, |(Card(*)(*))| for all cardinalities, and |*| for all upper bounds and verify that
  the constraints are satisfied. However, set lower bounds to |0|, cardinalities to |(Card(0)(0))|, and upper bounds to |0|, and verify that some
  constraints are violated (in fact, the constraint at the root of the expression is already violated).

  In the next chapter, we determine a least solution to the constraints, which means a least upper bound, a highest lower bound,
  and a most precise usage annotation. The remainder of this chapter delves more precisely into subjects encountered in this section.

\section{Language}
\label{sect.ExprLanguage}

  As mentioned before, the language in this chapter is a simply typed
  lambda-calculus without |let| bindings. The latter means no (recursive) |let|, but
  there are bindings by lambda abstraction:

%%[[wrap=code
  expr  ::=  int           -- integer expression (Int)
        |    var           -- variable expression (Var)
        |    expr + expr   -- plus operator (Plus)
        |    expr expr     -- application (App)
        |    \var -> expr  -- lambda abstraction (Lam)

%%]

  Types are assigned to each subexpression. The language of types is:

%%[[wrap=code
  tau  ::=  Int      -- tycon int (Int)
       |    (->)     -- tycon arrow (Arrow)
       |    tau tau  -- type application (App)
%%]

  We assume that all programs are correctly typed according to the type
  system in Figure~\ref{RulerUniquenessExamples.E.expr.base}. In this specification of the type
  system, |Gamma| is the environment that contains a type for each identifier
  in scope, and |tau| represents types. An integer expression has type |Int|. The type of a variable is recorded in the
  environment. The result and operands of an addition are |Int|s. When applying a function to a value, the parameter
  type and argument type should unify. Finally, a lambda abstraction brings the type of an identifier in scope, which
  means into the environment |Gamma| of the body.

  \rulerCmdUse{RulerUniquenessExamples.E.expr.base}


\section{Types, Annotations and Constraints}
\label{sect.TpAnnConstr}

  For the uniqueness type system, we extend the language of types to include
  the annotations encountered in the examples. These annotations are
  attached to type constructors:

%%[[wrap=code
  utau         ::=  Sup(Int)((LowerBound,c,UpperBound)))                             -- tycon int
               |    Sup(->)((LowerBound,c,UpperBound))                               -- tycon arrow
               |    utau utau                                                        -- type application

  c            ::=  (Card(Usage)(Usage))                                             -- cardinality annotation
  LowerBound   ::=  1 | 0                                                            -- lower-bound usage-count annotation
  UpperBound   ::=  0 | 1 | *                                                        -- upper-bound usage-count annotation
  Usage        ::=  0 | onemin | 1 | oneplus | *                                     -- cardinality annotation
%%]

  Why annotate the type constructors? Types describe the structure of a value in
  a concise way. A type constructor corresponds with a certain area of memory.
  For example, the |Int| type constructor represents all bits of an integer value.
  But in |List Int| (algebraic data types are introduced later in this master's thesis, Chapter~\ref{chapt.DataTypes}),
  the |List| type constructor represents the spine of a list, and the |Int| type constructor
  represents each element of the list (Figure~\ref{fig.ListRep}). In fact, how values are treated depends on
  an operation semantics (for example, Peyton Jones~\cite{DBLP:journals/jfp/Jones92a}), although we leave that implicit in
  this master's thesis.

\begin{XFigFigure}{}{list-rep}{Representation of a |List| in memory}{fig.ListRep}
\end{XFigFigure}

  Each bit of the list belongs to a single type constructor, the \emph{corresponding}
  type constructor. The cardinality of a single bit, is the cardinality of the
  corresponding type constructor. Or, the other way around, the cardinality of a
  type constructor is the \emph{join} over all the cardinalities of the bits that correspond
  to the type constructor. So, the reason is that the type constructors allow us to specify
  cardinalities of bits in a concise way, although we loose the ability to give different
  cardinalities to bits represented by the same type constructor.

  A related question is: why is the arrow type constructor annotated? There are
  several reasons. From a practical view considering code generation: functions
  are also values: \emph{closures}. Such a value is represented by an area of
  memory, and can have a cardinality like any other value. From a more
  theoretical point of view, functions that are used exactly once have the property that they can
  be safely inlined~\cite{Wansbrough:PhDThesis}. So, the arrow type constructor
  requires an annotation as well.

  \subsection{The annotations}
  \label{sect.partialorderings}

  In this section, we introduce the annotations on a type constructor, their values and some orderings on this
  values. A type constructor contains
  a triple with a lower-bound usage-count annotation (which we call the lower bound),
  a cardinality annotation, and an upper-bound usage-count annotation (which we call the upper bound). We
  consider these annotations in more detail and define some orderings on it which will be used when
  checking constraints or inferring values later (see the summary at the end of this section).
  
  The lower-bound usage-count annotation |LowerBound| on a type constructor of a type originating from
  expression |E|, specifies that the value of |E| is used at least |0| or |1| times via
  |E|. A lower bound of |0| means that there is no guarantee that the value is used via |E|.
  The |LowerBound| values are totally ordered with |1 leqL 0|\footnote{All the |leq| relations that we define are partial orders.}. Note that the
  relation |leqL| corresponds to the relation |>=| if the |LowerBound| values are considered natural
  numbers. We use this relation later to specify that when we know that |E| uses its value at least
  once, that we are allowed to forget it and think that we do not have any guarantee about how often
  the value of |E| is used. The definition of lower bound values can be generalised to lower
  bounds up to some value |k|, but we will not complicate this description with this generalisation.

  The upper-bound usage-count annotation |UpperBound| is the dual of the lower-bound usage-count
  annotation. It specifies that the value of |E| is used at most |0|, |1|, or |*| times via
  |E|. An upper bound of |0| means that the value of |E| is never used via |E|. An upper bound of
  |1| specifies that |E| used its value at most once. It can occur that the value of |E| is never
  used via |E|, but an upper bound of |1| does not guarantee that. However, it does guarantee that
  |E| is not used twice or thrice via |E|. Finally, an upper bound of |*| means that the value of
  |E| is used an arbitrary number of times via |E|, but probably twice or more. The |UpperBound|
  values are totally ordered with: |0 leqU 1| and |1 leqU *|.
  The |<=| relation on natural numbers corresponds to the above relation. The above relation is used in
  the checks to allow relaxation of an upper bound to a higher upper bound.

  We use the |leqL| ordering to allow weakening of lower bounds, and the |leqU| ordening to weaken upper bounds.

  These two bounds are not independent of each other. The upper bound should be greater
  than the lower bound, which is defined by the following
  predicate |leqB|:

%%[[wrap=code
  leqB :: LowerBound -> UpperBound -> Bool
  0  leqB  _  =  True
  1  leqB  u  =  1 leqU u
  _  leqB  _  =  False
%%]

  This |leqB| predicate tests if the lower and upper bound are consistent with each other. For
  example, a lower bound of |1| is inconsistent an the upper bound of |0|. This predicate is
  used to verify the consistency of a triple. It is not used for weakening purposes.

  An cardinality annotation consists of two |Usage| values. The left |Usage| value defines the
  usage of the value via |E|, and the right |Usage| value defines the total usage of the
  value. The left |Usage| value must fit the two bounds (Figure~\ref{code.FitsInBounds}). The
  right |Usage| value is at most as specific as the left |Usage| value.

  We define several orderings on |Usage| values. We start with an ordering that is used in
  the definition for consistency of cardinality annotations. This ordering, |leqX|, allows
  the right-hand side of a cardinality annotation to deviate from the left-hand side. The
  amount of deviation is determined by |leqX|. If |a leqX b| then |a| does not
  conflict with |b|. There is a conflict when the left |Usage| value specifies that the
  value is used at least |k| times and the right |Usage| value specifies that the value is
  used strictly less than |k| times. For example, |a = 1| and |b = 0| conflict. The following
  partial order defines when two values do not conflict (see Figure~\ref{fig.conflict}):

%%[[wrap=code
  0        leqX  onemin
  0        leqX  oneplus
  1        leqX  oneplus
  onemin   leqX  oneplus
  onemin   leqX  *
  oneplus  leqX  *
%%]

\begin{XFigFigure}{}{conflict-lattice}{The does-not-conflict semi-lattice}{fig.conflict}
\end{XFigFigure}

  If the left-hand side of a cardinality annotation is |*|, then the only possibility is
  |*| for the right-hand side. If we do not know the usage of one particular occurrence
  of some value, then we neither know it for the aggregation of all occurrences. Another
  interesting example is |onemin leqX oneplus|. A specific occurrence of a value can
  be used at most time, but then it is still possible that the value is in total
  guaranteed to be used more than once. So, |leqX| is used to test if a cardinality
  annotation is valid (i.e. it is used as a predicate like |leqB|).

  Furthermore, we have a partial order for checking that one |Usage| value is more
  specific than another |Usage| value. If |a leqQ b|, then |a| is more specific than
  |b|. It is defined as follows (see also Figure~\ref{fig.specificness}):

%%[[wrap=code
  0        leqQ  onemin
  onemin   leqQ  *
  1        leqQ  oneplus
  oneplus  leqQ  *
%%]

\begin{XFigFigure}{}{specific-lattice}{A semi-lattice on specificness of |Usage| values}{fig.specificness}
\end{XFigFigure}

  The above ordering is (only) used in Chapter~\ref{chapt.Polyvariant} to specify which right-hand side
  values of a cardinality annotation are preferable over others. |Usage| values of |0| and
  |1| are preferable over |onemin| or |*| because they are more precise. We do not use it yet in this
  chapter, since all the annotations are already given. But in the next chapter, we infer the annotations
  and start with the lowest value according to |leqQ| and gradually weaken the results according to
  |leqQ| until a fixpoint is reached. We already mention this ordering here for completeness.

  Similar to |leqQ| is |leqP|, which also specify that one |Usage| value is more specific
  than another |Usage| value, but then for the left-hand side values of cardinality annotations:

%%[[wrap=code
  0        leqP  *
  onemin   leqP  *
  1        leqP  *
  oneplus  leqP  *
%%]

  The rationale behind this ordering is that the join between the left-hand side
  values of two cardinality annotations, does not violate the lower bound and upper bound corresponding
  to these values. In the next chapter, there is a fixpoint iteration phase that starts with the most
  precise values for |leqP| that are possible for the bounds that were derived, which are then
  weaked according to |leqP| until a fixpoint is reached. In order not to violate any bounds during
  this weakening, weakening to |*| is only allowed, since |*| never violates any bounds.

  We now only need two more orderings: one to weaken left-hand sides of cardinality annotations, and
  one to weaken the right-hand side of cardinality annotations. This orderings are subjected to
  compiler optimisations.

  We define an ordering for coercions on the right-hand side |Usage| values of
  a cardinality annotation. A value with a total usage of |u| may be relaxed into a
  value with total usage |u'| (denoted by |u' leqZ u|) if there is a coercion function that changes a value
  with usage of |u| to a value with usage |u'|, such that optimisations of the compiler
  are still valid.

  For example, we can coerce a value with total usage of |onemin| to
  a value with total usage of |*| by means of the identity function if we assume that
  the compiler only uses cardinality annotations to insert code for destructive
  updates on unique values. The reason for this particular example is that due to the
  fact that the coercion is the first use of the value, that there can only be unused
  references (besides the coercion) to the value that consider it to be used at most once.
  And after the coercion, any active reference assumes that the value is used in an
  arbitrary way, such that no inplace updates can be performed on it. On the other hand,
  if the compiler generates code that allocates values with a total usage of |onemin| on
  a special compile-time garbage collected heap, then such a coercion is not allowed,
  unless there is an coercion function inserted into the generated code that copies the
  value to a normal garbage collected heap.

  So, it depends on optimisations of the compiler and the availability of coercion functions
  to allow certain coercions between right-hand side values of cardinality annotations.
  Therefore, by default |leqZ| is an equality relation, but we assume that it can be a
  subset of |leqS| with left and right arguments swapped. Note that |a leqZ b| defines
  that the total usage |b| can be relaxed by coercion to total usage |a|. This is the inverse direction compared to the other
  orderings in this section. This is intentional: the two bound annotations and the
  left-hand side value of a cardinality annotation combine usage information of individual
  occurrences of a value into usage information about the total usage of some value. Subsequently,
  this aggregate result is passed back to the individual occurrences via the right-hand side
  value of the cardinality annotations. We are only allowed to forget some property about the
  total usage of a value, if our uses of the value do not conflict with optimized uses of the
  value at other places, except by doing some additional administrative work (the coercion).

  We define a similar ordering as the ordering above for left-hand side of a cardinality
  annotation is relaxed. If |a leqS b|, then |a| can  be relaxed to |b|. This ordering
  is typically an equality relation, unless a relaxation does not conflict with optimisations
  of the back-end or can be resolved using a coercion function.

  Or in other words: we can relax the left-hand side of a cardinality annotation only
  to |*|. However, there is an important restriction here: if we make a relaxation for
  one particular occurrence of some value, then we must make this relaxation for all
  annotations of this particular occurrence. For example,

  The orderings on the left-hand side and right-hand side of a cardinality annotation can be
  combined into a single ordering on cardinality annotations as a whole:

%%[[wrap=code
  (Card(a)(b)) leqC (Card(c)(d))
    =   a  leqS  c
    &&  b  leqZ  d
    &&  a  leqX  b
    &&  c  leqX  d
%%]

  This ordering tells us that |a| can be weakened to |c|, and |b| can be weakened to |d|, if
  there is a coercion from |a| to |c| and from |b| to |d|, and both |a| and |b|, and |c| and |d|,
  do not conflict with each other.

  So, to summarize, we have three orderings used for weakening of results:
  \begin{itemize}
  \item |leqL| for the lower bound;
  \item |leqU| for the upper bound;
  \item |leqC| for the cardinality annotation (with |leqS| for the left-hand side and |leqZ| for the right-hand side).
  \end{itemize}
  And there are some orderings that are basically predicates:
  \begin{itemize}
  \item |leqB| for the two bounds;
  \item |leqX| for the left-hand side and right-hand side of a cardinality annotation.
  \end{itemize}

  \subsection{Triple consistency}

  A triple is consistent if the left-hand side of the cardinality annotation fits into the boundaries given by the two boundary
  annotations, and the left-hand side of the cardinality annotation is consistent with the right-hand side. See Figure~\ref{code.FitsInBounds} for a specification.
  We do not allow a |Usage| value that might violate the bounds. For example, the |Usage| value |oneplus| is not allowed when the upper bound is |0| or |1|, because
   `at least zero' or 'at least once' does not guarantee that the upper bound is violated. We make one exception to this rule for |*|.
   It always fits the bounds. We know that once |*| has been derived for an individual occurrence of a value, that the value in total
   will have a |Usage| value of |*|. Nowhere in the program can guarantees be made about a value with |Usage| value of |*|, so the
   bounds can be ignored for this value. Strictly speaking, this is not required: we could enforce a stronger notion of fitting and require that the boundaries itself are relaxed to
  |0| for the lower bound or |*| for the upper bound when the |Usage| value is |*|. However, in Chapter~\ref{chapt.Polyvariant}, we present an
  approach that infers the annotations, and the above relaxation allows us to infer lower and upper bounds separately from the cardinality annotations
  (Figure~\ref{code.iterate}).

  \begin{CodeFigure}{}{Consistency of triples}{code.FitsInBounds}

%%[[wrap=code
  tripleConsistent (a, (Card(b)(c)), d)
    =   a  `leftFit`   b
    &&  b  `rightFit`  d
    &&  b  leqX        c
    &&  a  leqB        d
%%]
\\
%%[[wrap=code
      leftFit :: LowerBound -> Usage -> Bool
      leftFit  0  _        =  True  -- bound gives no info
      leftFit  _  *        =  True  -- `don't know' fits bounds
      leftFit  1  1        =  True
      leftFit  1  oneplus  =  True
      leftFit  _  _        =  False
%%]
\\
%%[[wrap=code
      rightFit :: Usage -> UpperBound -> Bool
      rightFit  _       *  =  True  -- bound gives no info
      rightFit  *       _  =  True  -- `don't know' fits bounds
      rightFit  0       1  =  True
      rightFit  1       1  =  True
      rightFit  onemin  1  =  True
      rightFit  0       0  =  True
      rightFit  _       _  =  False
%%]
  \end{CodeFigure}

  The orderings are important. The analysis gets as input an annotated
  program and produces a set of constraints that hold between the annotations,
  if the annotations are valid. The semantics of these constraints make heavy
  use of the fact that one annotation is greater or equal to another annotation,
  as we will see in Section~\ref{Sect.CheckingConstraints}.

  There are three types of constraints for the type system in this chapter:

%%[[wrap=code
  constr  ::=  (LowerBound,c,UpperBound)  =>=            (LowerBound,c,UpperBound)                   -- coercion
          |    (LowerBound,c,UpperBound)  (Sub(=>=)(s))  (LowerBound,c,UpperBound)                   -- coercion (ignores use)
          |    (LowerBound,c,UpperBound) \*/ ... \*/ (LowerBound,c,up) <= (LowerBound,c,UpperBound)  -- aggregation
%%]

  As demonstrated in the examples, the coercion constraint (|=>=|) is used to propagate usage
  information. It specifies that the lower bound on the left-hand side is greater or equal
  than the lower bound on the right-hand side (|left \leqL right|). Vice versa, it specifies that
  the upper bound on the left-hand side is smaller or equal to the upper bound on the
  right-hand side (|left leqU right|). Finally, it specifies how the cardinality annotations
  are relaxed: for the left-hand side |Usage| value from left to right, and for the right-hand side
  |Usage| value from right to left. In the last case only when there is a coercion.

  With the coercion constraint, we essentially check that all boundary information is
  properly propagated from outermost expression to innermost expression, from
  body to parameters (Figure~\ref{fig.flow}). The cardinalities of values bound to identifiers are treated separately
  for each use-site of an identifier and added to each other by using the aggregation
  constraint |\*/|. Section~\ref{Sect.CheckingConstraints} describes how the constraints are
  checked.

\begin{XFigFigure}{}{unq-flow}{Count flow}{fig.flow}
\end{XFigFigure}

\section{Gathering constraints for first-order functions}
\label{Sect.ConstraintGathering}

  This section lists type rules for the uniqueness type system. Figure~\ref{RulerUniquenessExamples.U1.prog.base} defines
  that an annotated program is valid when the gathered constraints are satisfied. Section~\ref{Sect.CheckingConstraints}
  deals with constraint satisfiability. Constraints are gathered according to the expression type rules in
  Figure~\ref{RulerUniquenessExamples.U1.expr.base}. The constraints are gathered bottom up: this only holds if all
  functions are first order. In the next section (Section~\ref{Sect.HigherGathering}), we present type rules that
  support higher-order functions (which are slightly more complicated). We will now consider the rules in more detail.

  \rulerCmdUse{RulerUniquenessExamples.U1.prog.base}

  The type rule for the whole program (Figure~\ref{RulerUniquenessExamples.U1.prog.base}) states that the resulting expression has a lower and upper bound of |1|. By assuming
  that all the triples are consistent, this means that the resulting expression is allowed to have a cardinality of which the left-hand side
  is either |1| or |*|, although the total usage may be any |Usage| value except |0|. We pattern
  match on the annotated type of the expression to obtain the annotation |delta| on the outermost type constructor and generate a constraint
  that specifies that the lower bound is at least |1| and the upper bound is at most |1|. This constraint, and the
  constraints gathered from the expression itself, must be satisfied for the program to be valid according to
  the uniqueness type system.

  Types are written in two ways in the type rules. A type written as |utau| has annotations. A type written as
  |tau| has no annotations. We sometimes write |(Sub(tau)(a))| to refer to |(Sub(utau)(a))| without annotations.
  A |utau| is also denoted as |Sup(tau)(delta)|, where |delta| is the outermost\footnote{In this chapter, this is the
  triple on the outermost type constructor of the type expression. In the presence of algebraic data types, this is the outermost
  annotation on the result-kind of the type expression.} annotation.

  The structure of the type rules of Figure~\ref{RulerUniquenessExamples.U1.expr.base} is as follows. |Gamma| represents an environment that contains mappings from an identifier to a
  type (not annotated). The |e| stands for an expression with the annotated type |utau|. Finally |zeta| stands for a set of generated constraints.

  A few words on syntax: we write |(Sub(zeta)(1)) (Sub(zeta)(2))| to denote a constraint set obtained by taking the union of
  |(Sub(zeta)(1))| with |(Sub(zeta)(2))|. We write |(Sub(tau)(a)) <=> (Sub(tau)(b))| for the unification of |(Sub(tau)(a))|
  with |(Sub(tau)(b))|. Finally, unbound identifiers such as |delta| in the |Var| and |Lam| rule, specify that there are
  no limitations on that identifier.

  \rulerCmdUse{RulerUniquenessExamples.U1.expr.base}

  Constraints for an expression are gathered by a syntax directed traversal over the expression.
  The case for integers is the easiest: integers can be produced for any usage annotation and nothing has to be checked for them. We neither have to check anything
  for the use-sites of identifiers, since we deal with these identifiers in the case for lambda abstraction. The idea is that the occurrences of identifiers are independent,
  and we combine the results at the lambda abstraction. This works only when the identifiers are not functions. If an identifier is a function, we need the constraint
  set corresponding to the function (Section~\ref{Sect.HigherGathering}).

  The case for integer addition is slightly more complicated. Aside from consistency, there are no demands on the uniqueness
  component of the result of the addition. On the other hand, we check that the upper and lower bound annotations of the parameters are
  properly propagated from result of the addition to the arguments of the addition. For that, a |(Sub(=>=)(s))| constraint is generated
  between the triple on the result type and the triples on the argument types.

  The function application is perhaps the most difficult case in the uniqueness type system. Three things have to be done: check
  that the bounds of the function are in agreement with the bounds of the function application. Check that the bounds of the
  function application and the cardinality annotation are in agreement with the bounds and the cardinality annotation of the value of the
  function. Finally, check that the bounds and the cardinality annotation of the argument is in agreement with the bounds and usage
  annotation of the parameters.

  For checking propagation, we bring to the attention that the value passed to a function, or the value returned by the function, can
  be a function itself. Propagation deals with all annotated type constructors in the type to make sure that argument and parameter, and
  function result and result, are properly connected. Note that variance plays a role here: the direction of an argument of a function
  is the opposite to the result of the function. Suppose that a function |f| is passed to function |g| as parameter, then |g| applies the
  function, and passes some argument |x|. Propagation is from |x|, to the parameter of |g|, and inside |g| to the result-value of |g|. The
  propagation of boundaries and usage information for such an annotation is the other way around than the usual flow. In Figure~\ref{RulerUniquenessExamples.U1.flow.base} we list the
  type rules that walk over the type and generate the |=>=|-constraints for each two corresponding annotations in the proper direction.

  \rulerCmdUse{RulerUniquenessExamples.U1.flow.base}

  The last case to deal with is lambda abstraction. We use an auxiliary rule that gathers all annotated types of the use-sites of the
  identifier of the lambda and turns these into an aggregation constraint. There is no constraint generated between the triple of the
  result of the body and the result-part of the annotated type of the lambda function. As is visible in the type rules, we force the annotated types to be exactly the same. This
  means that we cannot weaken the annotations of the body. But, a function application can weaken the bounds and usage information
  of the result, if needed.

  As a final note about the type rules: the type system can be formulated in a less complicated, but not syntax directed, way. By adding
  an additional case for coercions, the places where we generated a |=>=|-constraint can be extracted and handled by this special
  non-deterministic rule. However, that would make it unclear at which places the |=>=| constraint is generated, and that is actually
  what we want to make explicit, so we choose for a more elaborate, syntax directed, representation of the type rules.


\section{Gathering constraints for higher-order functions}
\label{Sect.HigherGathering}

Consider the expression |(\x -> x + x) 3|. Since |x| is not a function, it only has one triple (say |delta|) that describes
how |x| is used. With only a single triple, there cannot be constraints between triples on the type of |x|. Since two
occurrences of |x| can have a different triple than |delta|, there is actually a constraint for |x|: the aggregation constraint
generated at the lambda. Conceptually, this constraint belongs to the (empty) constraint set of the two occurrences of |x|. However,
there is no need to transport this constraint set to the occurrences of |x| because it is already included in the constraint set
generated for the lambda. Figure~\ref{fig.unqConstrProp} illustrates this: the thick lines indicates the propagation of constraint
sets from the leafs to the root. The dotted lines correspond to conceptual constraint sets.

\begin{XFigFigure}{}{unq-constr-prop}{Propagation of constraint sets for first-order functions}{fig.unqConstrProp}
\end{XFigFigure}

Now consider the expression |(\f -> f 3 + f 3) (\x -> x)|. Since |f| is a function, there are relations between triples occurring
on the type constructors of the type of |f|. In this case, there is a coercion between the result of |f| and the argument of |f|.
The aggregation constraint only aggregates the triple on the spine of |f|, not the triples on the argument and result part of the
type of |f|. This directly means that we do not check if each occurrence of |f| is correctly used according to the expression
that is passed as |f|!

Since all annotations in this chapter are monovariant, we have an easy way out of this problem. The triples deeper into the
type of an occurrence of |f| need to be equal to the corresponding triple in the definition-type of |f|. For example, if
the definition site of |f| has the type |f :: (Sup(Int)((1,(Card(1)(1)),1))) (Sup(->)((1,Card(oneplus)(oneplus),*))) (Sup(Int)((1,(Card(1)(1)),1)))|,
then the occurrences of |f| are allowed to have a different annotation for the spine, such as:
|(Sup(Int)((1,(Card(1)(1)),1))) (Sup(->)((1,(Card(1)(oneplus)),*))) (Sup(Int)((1,(Card(1)(1)),1)))|, but not:
|(Sup(Int)((1,(Card(*)(*)),1))) (Sup(->)((1,(Card(1)(oneplus)),*))) (Sup(Int)((1,(Card(*)(*)),1)))|. We can enforce this by
generating an equality constraint between these deeper triples of |f| during the generation of an aggregation constraint.

However, in the next chapter (Chapter~\ref{chapt.Polyvariant}) we support polyvariant cardinality annotations, such that we are
able to apply |f| to arguments with different cardinalities. This requires a rather complicated propagation of constraint sets,
as the use-sites of a higher-order parameter need the constraint set belonging to the expression that is passed as higher-order
argument. Figure~\ref{fig.unqConstrProp2} illustrates this. The thick lines represents the leafs to root propagation of
constraint sets as presented in Section~\ref{Sect.ConstraintGathering}. The tiny dotted lines are the original aggregation
rules that only aggregate the spine annotation of use-sites of parameters. The dotted lines represent the propagation of
constraint sets from argument expression to use site of a parameter. For example, the constraint set for the value |3| (which is empty)
needs to be passed at the function application with |f| as the constraint set of the use-site of |x| in the constraint set
of |f|. Likewise, at the application at the root, the constraint set of the argument should be passed as the constraint set
for the two occurrences of |f| (this constraint set is not complete as it still requires a constraint set, which is provided
by an application of |f|). We solve this constraint passing problem in the next chapter in a similar way as the spread
function in Heeren~\cite{heeren05phd-errormsg}, with receive points indicated using a special |Inst| constraint to represent
a receive point and spread points as a special annotation on the arrow type constructor.

\begin{XFigFigure}{}{unq-constr-prop2}{Propagation of constraint sets for higher-order functions}{fig.unqConstrProp2}
\end{XFigFigure}

  As preparation for the next chapter, we present a set of type rules that implement the above approach. It does not have
  any benefits for this chapter due to monovariance, but serves as a preparation for Chapter~\ref{chapt.Polyvariant}.
  Figure~\ref{RulerUniquenessExamples.U2.expr.base} lists the modified set of type rules. We now have two additional
  environments and function arrows have an additional annotation (a unique identifier). The environment |Psi| consists of
  mappings from a unique identifier |beta| to a constraint set. The environment |Phi| consists of mappings from
  identifiers of the expression to such a unique identifier |beta|. The idea is that we give each parameter of a function
  a unique identifier |beta|, which is recorded in |Phi| at a lambda abstraction. This |beta| represents a receive point
  of a constraint set. At each use of an identifier, we lookup what the corresponding receive point is and demand that the
  future constraint set will become the constraint set of the use of the identifier. Because this |beta| ends up as
  annotation on the function arrow and is used during unifications, we know at applications of this function how to refer
  to this |beta|. The future constraint set is then provided by the function application by demanding that the receive
  point |beta| corresponds with the constraint set resulting from argument expression.
  
  \rulerCmdUse{RulerUniquenessExamples.U2.expr.base}
  
  Note that a constraint set of node |e| in the abstract syntax tree cannot spread to a node that is a child of |e| due
  to the fact that we only spread from argument to function in a function application. This ensures that we can write this
  spreading concisely using a few AG attributes: unifications already took place so we know what |beta| is at the
  function application and at the use-sites of parameters. For a function application, we can then just add the synthesized
  constraint set of a function application paired with |beta| to the inherited environment |Psi| of the function expression,
  take out the constraint set at the use sites of the corresponding parameter, and then synthesize the constraints of the
  function expression, argument expression, and the coercion constraints of the function application as the constraint set
  of the function application. This is not the case for a recursive |let|. However, a solution will be presented in
  Chapter~\ref{chapt.Recursion}, based upon instantiation and the constraint graphs of Chapter~\ref{chapt.Polyvariant}.


\section{Checking constraints}
\label{Sect.CheckingConstraints}

  The following definition defines precisely when a constraint is satisfied or not:

%%[[wrap=code
satisfied :: Check
satisfied  (a =>= b)                                   = a `coercionSatisfied` b
satisfied  (a (Sub(=>=)(s)) b)                         = a `softCoercionSatisfied` b
satisfied  ((Sub(a)(1)) \*/ ... \*/ (Sub(a)(2)) <= a)  = [(Sub(a)(1)) ... (Sub(a)(n))] `aggregationSatisfied` a
%%]

  This function is lifted to work on constraint sets as a whole.

  \subsection{Coercion constraints}

  For a coercion constraint, the lower bound of the left-hand side should be
  greater than the lower bound of the right-hand side. It is the other way around
  for the upper bound. If the coercion is weak, then the cardinality annotation is ignored,
  otherwise the right-hand side should be more specific than the left-hand side:

%%[[wrap=code
coercionSatisfied (a, b, c) (d, e, f)
  =   a  leqL  d
  &&  b  leqC  e
  &&  c  leqU  f
softCoercionSatisfied (a, b, c) (d, e, f)
  =   a  leqL  d
  &&  c  leqU  f
%%]

  This constraint is generated in such a way that we may weaken what we know of the
  right-hand side, to obtain the left-hand side. Depending on code generation, some
  coercion function may need to be inserted, for example, to move a value from a
  compile-time garbage collected heap to a runtime garbage collected heap. For a code
  generator that only selects special operations for types that are used at most once,
  no coercion function is required.

  \subsection{Aggregation constraint}

  For the aggregation constraint, we conservatively approximate the upper and lower bound. Things
  are a bit more complicated for the cardinality annotation. We check that the left-hand side of the cardinality annotation
  is properly split up to the individual use sites (Figure~\ref{splitFunc}) and that the right-hand side is equal for
  all use-sites. We mean with this that if a value is linear, that the left-hand side of the cardinality annotation is
  linear for one use site, and not used for the other use sites. For the right-hand side of the cardinality, we check
  that all use-sites consider the total usage of the value to be linear. See Figure~\ref{code.sumsat} for the
  definition.

  \begin{CodeFigure}{}{The isSplit function.}{splitFunc}
%%[[wrap=code
isSplit as 0        = all (== 0) as
isSplit as 1        = let  (eq0, neq0) = partition (== 0) as
                      in   length neq0 == 1
                           && head neq0 == 1
isSplit as oneplus  =  length as > 0
                    && any (== oneplus) as
                    && all (/= 0) as
                    && all (/= 1) as
isSplit as onemin   = all (== onemin) as
isSplit as *        = all (== *) as
%%]
  \end{CodeFigure}

  \begin{CodeFigure}{}{aggregation constraint satisfaction}{code.sumsat}
%%[[wrap=code
aggregationSatisfied [((Sub(a)(1)), (Card(Sub(b)(1))(Sub(c)(1))), (Sub(d)(1))), ..., ((Sub(a)(n)), (Card(Sub(b)(n))(Sub(c)(n))), (Sub(d)(n)))] (a, (Card(b)(c)), d)
  =   (Sub(a)(1)) `max` ... `max` (Sub(a)(n)) leqL  a
  &&  isSplit [(Sub(b)(1)), ..., (Sub(b)(n))] b
  &&  (Sub(c)(1)) === ... === (Sub(c)(n))
  &&  (Sub(d)(1)) + ... + (Sub(d)(n)) leqU  d
%%]
  \end{CodeFigure}

  Note that when $n = 0$, |(Sub(a)(1))  `max` ... `max` (Sub(a)(n)) === 0| and |(Sub(c)(1)) +  ...  +  (Sub(c)(n)) === 0|.
  If an identifier does not occur syntactically, then the value cannot be touched through that identifier, and the lower
  bound corresponding to the type of the identifier is forced to |0| and the upper bound can be anything.

  All occurrences of an identifier point to the same value. So, if one occurrence of an identifier has a lower bound
  of |1|, it means that the occurrence is evaluated at least once, so the value is used at least once. We approximate the
  lower bound by taking the maximum of all lower bounds.

  At this moment, we do not distinguish between parallel and sequential occurrences of
  values. For parallel occurrences, we can use the maximum of the upper bounds instead
  of the sum, which is a better approximation. And in a similar way take the sum of the
  lower bounds instead of the maximum (note the duality here). We discuss this subject
  in Chapter~\ref{chapt.Parallel}.

\section{Strictness?}
\label{sect.strictness}

  As we mentioned in Chapter~\ref{chapt.Introduction}, we can also infer strictness with our approach. Strictness is
  defined as follows: consider a function |f = \x -> ...| and the application |r = f bottom|. If reduction of |r| to
  weak-head normal form results into |bottom|, then |f| is strict in |x|.

  After performing the analysis that we explained in this chapter, we know for some parameters that they are
  used. This information almost tells us that the parameters are strict, but not entirely: in our analysis it is
  possible that we consider a value used, because the result of the function is reduced further than weak-head
  normal form.

  But, we can obtain strictness properties of a function |f| with result type |r|. Suppose we only have the expression
  of |f|. If we use |(1, (Card(1)(oneplus)), 1)| for the outermost annotation on |r| and |(0, (Card(0)(0)), 0)| for
  all other annotations of |r|, and expect a valid annotation, then |f| is strict in those parameters that can have a
  cardinality annotation with |oneplus| or |1| as left-hand side value. An optimisation is that we can |seq| (Section 6.2 of the Haskell 98 report~\cite{DBLP:journals/jfp/Jones03e}) the
  parameters before applying them to the function. The annotations on the types further specify how deep the
  |seq| function can evaluate the value.

\section{Conclusion}

  We showed in this chapter what we mean with uniqueness typing, albeit with a simple language. Our approach
  consists of a set of type rules that specify when a program is correctly annotated with cardinality annotations.
  We turned this problem into a constraint satisfaction problem, which gives us a separation between the
  gathering of the constraints and checking them. In the next chapter, we show that the
  constraints also allow us to \emph{infer} cardinality annotations, instead of requiring that they are supplied
  by the programmer.

  In this chapter, we also stated that cardinality annotations are not sufficient. We required lower-bound and upper-bound annotations
  as well. In the next chapter, we switch to inferring cardinality properties, and there we infer these bounds as well.

%%]
