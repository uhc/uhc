%%[abstract
Haskell's class system provides a programmer with a mechanism to implicitly pass parameters to a function.
A class predicate over some type variable in the type signature of a function induces the obligation for the caller
to implicitly
pass an appropriate instance of the class to the function.
The class system is programmed by providing class instances for concrete types,
thus providing, for each class, a unique mapping from types to instances.
This mapping is used whenever an instance for a class predicate over some type is required.
Choosing which instance to pass is solely based on the instantiated type of the class predicate.

Although this mechanism has proved to be powerful enough for modelling overloading and
a plethora of other programming language concepts,
it is still limited in the sense that multiple instances for a type cannot exist at the same time.
Usually one can program around this limitation by introducing dummy types,
which act as a key to map to additional instances;
but this indirect way of allowing extra instances clutters a program and still is bound to
the finite number of types statically available in a program.
The latter restriction makes it impossible to dynamically construct instances,
which, for example, depend on runtime values.

In this paper we lift these restrictions by means of local instances.
Local instances allow us to shadow existing instances by new ones and to construct
instances inside functions, using function arguments.
We provide a translation of class and instance definitions to Constraint Handling Rules,
making explicit the notion of ``scope of an instance'' and its role in context reduction for instances.
We deal with the ambiguity of choosing between instances
by using a framework for heuristically choosing between otherwise overlapping instances.
%%]

%%[introduction
%%@TopicExplImpl.bodyIntro1

These definitions are used by the class system whenever the use of a value requires a class predicate to be satisfied.
For example, the expression |f 3 4| requires |Eq Int| to hold,
satisfied by the instance declaration for |Eq Int|.
Additionally, an evidence based translation implicitly passes a dictionary
for each predicate occurring in the type of the function: |f 3 4| translates to |f eqDInt 3 4|.

For the purpose of \thispaper, the key design choices of the type class mechanism are:

\begin{itemize}
\item The class system chooses which instance is used to satisfy a predicate, and consequently which dictionary to pass implicitly.
\item The class system makes its choice based on the type(s) over which a class predicate ranges.
\item The only way a programmer can steer the class system is by providing class and instance declarations,
  and explicit type signatures for let-bound identifiers.
\end{itemize}

These design choices have led to, often ingenious, type level programming and class system extensions to support this,
most notably multiparameter type classes and functional dependencies.
However, the basic mechanism of type based choice of an instance remains the same.
For some programming problems this can lead to contrived code.
For example, suppose we need to compare two |Int|s modulo 2 and still want to use the class system:

%%@TopicExplImpl.instanceEqIntMod2

How do we instruct the class system to use this instance declaration instead of the previous, default, one?
We can't, at least not without modifying the class |Eq| and its instances,
or modifying the encoding of the |Int| value passed to |(==)|.
We further explore alternate |Int| encodings by means of a wrapper data type.
Although both instances satisfy the predicate |Eq Int|, we have to choose between two dictionaries,
without a means of making the choice: we have overlapping instances.
We can avoid this by providing enough additional type information to make a choice:

%%[[wrap=code instanceEqIntWithExtraType
data Default   = Default
data Mod2      = Mod2
data Wrap l a  = W l a

instance Eq a => Eq (Wrap Default a) where
  W _ x == W _ y = x == y

instance Eq (Wrap Mod2 Int) where
  W _ x == W _ y = (x `mod` 2) == (y `mod` 2)

f :: Eq a => a -> a -> Int
f = \x y -> if x == y then 3 else 4

v1 = f (W Default  (2::Int))  (W Default  4)
v2 = f (W Mod2     (2::Int))  (W Mod2     4)
%%]]

We wrap the |Int| value in the |Wrap| data type together with a value |Mod2| of which the type determines
to use instance |Eq (Wrap Mod2 Int)|.
If we use local instances instead, the above clutter is avoided:

%%[[wrap=code
f' p q =  let  instance Eq Int where
                 x == y = primEqInt (x `mod` 2) (y `mod` 2)
          in   f p q
%%]]

Function |f'| invokes |f| within the context of an overriding instance for |Eq Int|.
The static nesting structure of |let| expressions provides the additional information for the class system
to choose between the default |Eq Int| instance at the global level, and the local |`mod` 2| based |Eq Int| instance.

Local instances also allow us to tackle the so-called configuration problem \cite{kiselyov04impl-config}
more directly.
Configuration means the parameterization of code with additional data,
without this being visible in the form of additional parameters in the configured code.
For our example this means that we want to test for equality |`mod` n| for arbitrary |n| instead of fixed |`mod` 2|,
and solved for our |Wrap| example by:

%%[[wrap=code
data ModN  n    = ModN n

instance Eq (Wrap (ModN Int) Int) where
  W (ModN n) x == W _ y = (x `mod` n) == (y `mod` n)

f' n = f (W (ModN n) (2::Int)  )  (W (ModN n) 4)
%%]]

However, Kiselyov's solution \cite{kiselyov04impl-config} differs from ours
because of their use of phantom types, that is, data types with type parameters without a corresponding runtime value.
For our |Wrap| example we then have:

%%[[wrap=code instanceEqIntWithExtraType
data Mod2
data Wrap'  l a  = W' a

instance Eq (Wrap' Mod2 Int) where
  W' x == W' y = (x `mod` 2) == (y `mod` 2)

v2 = f (W' 2 :: Wrap' Mod2 Int)  (W' 4)
%%]]

We get rid of the |l| typed field in |Wrap'|, |data Mod2| no longer needs a constructor,
and we pass type information via a type annotation instead of a value.
Taking this route further, one can hide much of this mechanism with clever type level programming.
However, the drawback is that we no longer can use |ModN| to pass additional data,
because we no longer pass any runtime data along with the type:
the resulting solution has become purely type based.
This is a closed world, and as a result we then cannot take (for example) a commandline parameter and turn it into
a configuration for the program.

Our solution using a local instance is as follows:

%%[[wrap=code
f' n p q =  let  instance Eq Int where
                   x == y = primEqInt (x `mod` n) (y `mod` n)
            in   f p q
%%]]

The bottomline is that additional information must be passed to a function,
and to solve this we either:

\begin{Itemize}
  \item wrap normal parameters with extra type related information steering the choice of an instance,
        possibly also including additional runtime available data;
  \item use phantom types instead to only pass type related information (\cite{kiselyov04impl-config}, not further explained here);
  \item override directly by means of a local instance.
\end{Itemize}

A solution without local instances always becomes cluttered because of the indirect way an instance is chosen via a type,
whereas local instances circumvent such an indirection.
This then is our motivation for looking into local instances.

%%]

%%[defLocalInst
A \IxAsDef{scope} is a program location, distinguishable on the basis of its lexical nesting position.
A \IxAsDef{scoped instance} is an instance for which we know its defining scope.
We distinguish between \IxAsDef{global scope} as the lexically outermost scope;
\IxAsDef{local scope} is defined as non-global scope.
In Haskell a normal module level instance corresponds to a globally scoped instance, or just global instance.

%%]
A \IxAsDef{global instance} is a normal module level Haskell instance.
A \IxAsDef{local instance} or \IxAsDef{non-global instance} is an instance declared in a nested expression,
where nesting is defined by Haskell's normal nesting language constructs.
The \IxAsDef{scope} of an instance uniquely defines the location within nested language constructs.
Scopes can be compared for visibility, to be defined more precisely later.
A \IxAsDef{scoped instance} is either a global or a local instance, distinguishable on the basis of its scope.
Note that in literature ``local'' sometimes means ``per module''.
However, as per module instances are exported globally anyway in Haskell,
we consider such instances to be global instances.

%%[problem
Although the idea of scoped (or local) instances already exists for some time
and is available in a limited form known as ``implicit parameters'' \cite{lewis00implicit-param},
to our knowledge scoped instances are neither available nor described previously.
We can see the following areas where the interaction between scoped instances, context reduction,
and type inference is problematic:
\begin{itemize}
\item Principal typing.
\item The location in the program where the need to prove a predicate arises.
\item Instances requiring other instances as their context.
\item Interaction with type signatures.
\end{itemize}

Before proceeding, we point out that 
all these areas share the same problem with instances: how to choose between them.
Such a choice already is an issue for `normal' overlapping instances.
The main underlying idea of \thispaper\ is to take this choice away from the language definition
because it cannot be made unambiguously anyway,
and to put it in the hands of the programmer.
Naturally, default situations still can be handled without programmer intervention,
but when necessary the programmer can specify exactly what a language tries to do automatically,
without burdening the programmer with known default situations.

We now further discuss the list of problems mentioned above.

\Paragraph{Principal typing}
Wadler \& Blott observed \cite{wadler88how-ad-hoc-poly} that allowing the following program led to loss of principal typing:

%%[[wrap=code
f =  let  instance Eq Int
          instance Eq Char
     in   (==)
%%]]

In his type system he could derive either |f :: Int -> Int -> Bool| or |f :: Char -> Char -> Bool| because of the presence
of the two instances, but not |f :: Eq a => a -> a -> Bool|.
The instantiation of the type of |(==) :: Eq a => a -> a -> Bool|
combined with the satisfaction of the instantiated predicate |Eq a| by either |Eq Int| or |Eq Char| leads to his possible derivations.
However, |(==)| does not even use the corresponding dictionaries, so this interaction seems unnecessary and artificial.
Part of the problem lies with
a check for satisfiability when the type of a value is established, usually as part of a generalization step for |let| bindings.
Such a check also conflicts with modularity because later additional instances may be defined,
and therefore this check is usually omitted.
Even for the following variant the two instances play no role and could well have been omitted:

%%[[wrap=code
f x y =  let  instance Eq Int
              instance Eq Char
         in   x == y
%%]]

However, the key observation is that as soon as a polymorphic type is instantiated with a more concrete type, and the necessity
to satisfy a predicate over this type arises, such local instances play a role:

%%[[wrap=code
f x y =  let  instance Eq Int       -- now used!
         in   x == y && x == 3
%%]]

In |x == y && x == 3|
the need for |Eq Int| arises within the scope of the local |Eq Int| instance, and its satisfaction
thus must take the presence of this instance into account.\footnote{We ignore the fact that 3 gives rise to a |Num| predicate.}
In terms of a solution for scoped instances, this means that the obligation to prove a predicate like |Eq Int|,
has to be annotated with the scope in which that happens.
And, although we lose principal typing, our solution for dealing with scoped instances offers a mechanism to
steer context reduction for the qualified part of an inferred type.
Therefore, scoped instances, when combined with type signatures (more about this later),
in practice offer a way to explicitly deal with
the consequence of the loss of principal typing.

\Paragraph{Location}
The above observation complicates matters, as demonstrated by the following example;
|y|'s type is not generalized over in function |g| because it still is free in |g|'s enclosing environment:

%%[[wrap=code
f x =  let  g y =  let  instance Eq Int     ^
                   in   x == y              -- (*)
       in   g 3
%%]]

We only get to know the type of |y| together with |f|'s parameter |x|,
which means that context reduction for the |Eq| predicate
over that type arising at (*) has to be done together with context reduction for |f|,
on a more global level.
There we find out that both |y| and |x| are of type |Int|, and that the nested |Eq Int| instance can be used.
Context reduction then still has to know about the local instance declaration, even for proofs on a more global level.

\Paragraph{Instances with context}

The combination of instances requiring other instances in their context, overlapping instances,
and local instances makes it rather difficult to predict what combination of instances is used to
satisfy |Show [[[v1]]]|, arising in |showTable|, in the following example for some type variable |v1|:

%%[[wrap=code
class Show a where
  show :: a -> [Char]

instance Show Char                          -- dShowChar
instance Show a =>  Show [a]                -- dShowL
instance Show [Char]                        -- dShowCharL

showTable hdr tbl 
  =  let  instance Show a =>  Show [[a]]    -- dShowLL
     in   show (map (\x -> x ++ x) hdr : tbl)

main = showTable ["Name", "DOB"]  [["G", "19830511"]
                                  ,["A", "19830208"]]
%%]]

What is the type of |showTable|, and along which path in \figRef{chr-redGraphShowTable}
do we reduce context, if we do context reduction at all?

%%[[wrap=code
showTable :: Show [[[a]]]  => [[a]] -> [[[a]]] -> [Char]
showTable :: Show [a]      => [[a]] -> [[[a]]] -> [Char]
showTable :: Show a        => [[a]] -> [[[a]]] -> [Char]
%%]]

\FigurePDF{t}{0.55}{redGraphShowTable}{Context reduction for showTable}{chr-redGraphShowTable}

The first type opts for no context reduction at all, whereas the second only uses the local instance |dShowLL|, and
the third has several alternative paths available to arrive at |Show v1|.
From the above problems we conclude the following:

\begin{itemize}
\item The proving machinery, declared instances and predicates all need to be aware of (their) scope.
\item The choice offered by local instances complicates making automatic choices during context reduction.
\end{itemize}

\Paragraph{Type signatures}

The role of type signatures becomes more significant:

%%[[wrap=code
e1 :: Int -> Bool
e1 x = x == 2

e2 :: Eq Int => Int -> Bool
e2 x = x == 2

f x =  let  instance Eq Int
       in   e1 x && e2 x
%%]]

Although currently not allowed
\cite{peytonjones03has98-rev-rep},
the type signature for |e2| implies that the decision which |Eq Int| to use is delayed until |e2| is called:
in |f| the local instance is used for |e2|, the global one for |e1|.
The presence of a class predicate in the type signature for |e2| introduces a scoped instance for the body |e2|.
Without local instances this makes no difference, because only one |Eq Int| is present.
%%]

%%[ourContribution
The awareness of scope and complexity of choice leads us to a solution which does not attempt to do the impossible,
which is always automatically making the right choice between instances.
Instead we aim for a design where ultimately the programmer has complete control over which instances are to be used.
In \thispaper\ we therefore propose a three stage process for dealing with making choices for local instances separately:

\begin{Itemize}
\item Translate class and instance declarations to an equivalent Constraint Handling Rule (CHR) representation,
      taking scope into account.
\item Solve constraints using the CHR representation, thereby generating all possible solution alternatives for context reduction.
\item Choose between solution alternatives by means of a separate framework.
\end{Itemize}

We focus on the translation to CHRs and the choice between solution alternatives as we feel that this is the novelty
of our approach.
We do \emph{not} deal with a type system in which our solution is to be embedded,
nor make claims about formal properties of our solution,
although we will point out what needs to be done in this area (\secRef{sec-chr-relatedwork}).
We emphasize that our solution should be seen as a proposed solution,
not as the proven correct solution within a theoretical framework.
We present part of our work in terms of Haskell, much in the spirit of ``Typing Haskell in Haskell'' \cite{jones99thih}.
A prototype system has been built and more extensively described by \blindcite{geest07cnstr-tycls-ext},
and has been integrated into the \blind{Essential Haskell (EH)} compiler
\blindcite{dijkstra04ehc-web,dijkstra05phd}.

We omit the description of a type system in which our context reduction takes place;
although type inference and context reduction interact,
these are largely separate issues.
Our approach can be part of any standard Hindley-Milner type inference algorithm
\cite{damas82principal-type} or be embedded in more recent type inference algorithms
which are already CHR based \cite{sulzmann98hm-constr,stuckey02theory-overloading}.

In summary, our contribution is:

\begin{Itemize}
\item Model scope for class predicates by means of CHR, and provide a different translation to CHRs as compared to Sulzmann et al. .
\item Provide a framework for expressing different context reduction strategies, applied to scoped instances in particular.
      The intention is to make the use of this framework available to the programmer, but this has not been done yet.
\item A prototype for the above, integrated in a Haskell compiler.
\end{Itemize}

%%]

%%[startingPointWork

  CHRs \cite{fruhwirth98theory-chr,fruhwirth03essence-constrprog} as used by Sulzmann et al. \cite{sulzmann98hm-constr,stuckey02theory-overloading}
  to describe and formalize Haskell's type system.
  Our use of CHRs for the class system is slightly different because we postpone any decision
  making for instances to a later stage.
  We also have to be more precise in dealing with type signatures.
  As we focus on the class system exclusively, we ignore the use of CHRs for the underlying type system itself.

  Techniques for improving type and class error messages are also constraint based
  \cite{heeren05class-direct,heeren05phd-errormsg,heeren05www-helium}.
  Their solution first solves constraints and then uses a representation of the solution to produce error messages;
  we use similar techniques to separately deal with choosing between instances.

  Design alternatives for a class system, in particular context reduction,
  were explored by Peyton Jones et al. \cite{peytonjones97typecl-explore}.
  Our framework for choices between instances allows to express such alternative context reduction strategies.

  GHC \cite{www04ghc} allows some form of programming the predicate proving machinery by means of pragmas,
  for example for choosing the most specific instance in case of overlapping instances.

  Named instances \cite{kahl01named-instance,scheffczyk01mth-namedinst} allow explicit named references to instances.
  This is a natural extension for being explicit in the choice between multiple instances,
  also experimented with in \blindcite{dijkstra04ehc-web,dijkstra05phd}.

Closest to our work are modular type classes \cite{dreyer07mod-tyclass}.
Module signatures correspond to classes, modules to class instances:
the class system is built on top of the module system.
Their scoping mechanism is bound to an explicit import (|using|) mechanism for modules,
similar to naming instances.
Only explicitly imported instances partake in context reduction.
Our work differs in that the notion of scope participates in choosing between otherwise overlapping instances;
more information is taken into account, and we aim at programmability of the decision process between instances.

Furthermore, there is a large body of work on type classes
\cite{jones93constr-class,jones00class-fundep,lewis00implicit-param,chakravarty04assoc-tp-class,chakravarty05assoc-ty-syn},
some of which is described in terms of CHRs
\cite{sulzmann98hm-constr,stuckey02theory-overloading,stuckey04exist-tycls,sulzmann06tycls-inf-multi-par,sulzmann07fundep-chr}.
Most of these are relatively independent of scoped instances.

%%]

%%[termsAndTypes
\Paragraph{Terms, types and predicates}

\figRef{chr-locinst-terms-types} shows the standard term and type language we assume for our discussion of scoped instances.
We have included \figRef{chr-locinst-terms-types} to clarify the minimal expected context of our work,
but we will not explicitly use it any further after this section.
Although the syntax allows local classes, we inhibit this.
We see no reason to inhibit instances nested within instances.
For simplicity we only consider single parameter type classes.
Overbar notation |Vec(x)| denotes (possibly empty) sequences of |x|'s, comma denotes concatenation,
|identv| lowercase variables, and |identc| uppercase constructors.

%{
%format t = sigma
%format pr = pi
%format dsig = "d_{sig}"
%format dval = "d_{val}"
\begin{TabularCenterFigure}{}{Terms and types}{chr-locinst-terms-types}%
%%@AppxNotation.termTableFormat
%%@AppxNotation.exprHeader
%%@AppxNotation.exprBasicInt
%%@AppxNotation.exprBasic
%%@AppxNotation.exprLetVecDecl
%%@AppxNotation.exprLamIdent
%%@AppxNotation.termSeparator
%%@AppxNotation.declHeader
%%@AppxNotation.declBasicTySigma1
%%@AppxNotation.declBasicVal1
%%@AppxNotation.declBasicValTySigma1
%%@AppxNotation.declExplImplBasic1
%%@AppxNotation.termSeparator
%%@AppxNotation.typeHeader
%%@AppxNotation.typeBasicMonoInt
%%@AppxNotation.typeBasicMono
%%@AppxNotation.typeSchemeMono
%%@AppxNotation.termSeparator
%%@AppxNotation.predHeader
%%@AppxNotation.typredBasic1
\end{TabularCenterFigure}
%}

\Paragraph{Constraints}

We use the following forms of constraint |Cnstr|, parameterized with predicate |varpi| and |info| used to postprocess and choose
between |Reduction| alternatives:

%%[[wrap=code
Cnstr   ::=     Prove       varpi
        |       Assume      varpi
        |       Reduction   varpi info ^^ {varpi1, ... , varpin}
%%]]

A |Prove varpi| constraint indicates a proof obligation for |varpi|,
an |Assume varpi| corresponds to an assumption for |varpi| introduced by a type signature,
and a |Reduction| corresponds to a reduction step from the ordered sequence |{varpi1, ... , varpin}| to |varpi|.
Depending on the problem at hand, |varpi| instantiates differently.
For our initial solution without scopes we instantiate |varpi| by: |varpi isbydef pred|.
%for our solution with scopes: |varpi isbydef (pred,scope)|, also
%denoted by |predscope|.
%Whenever we use |pred| where a |predscope| is expected, scope is irrelevant.
% A set of constraints is referred to by a constraint as well.
|CnstrVarpi(Cnstr)| denotes the |varpi| of a constraint |Cnstr|.
The empty set of constraints represents |True|.

\Paragraph{Constraints and entailment}

Entailment on predicates, shown in \figRef{MiscRules.entailn.all}, is standard \cite{jones94phd-qual-types}.
|prenv| holds the environment of class and instance definitions.
We allow ourselves notational looseness by allowing |pred| to denote a singleton whenever |preds| is expected.

\rulerCmdUse{MiscRules.entailn.all}

\begin{Definition}[Constraint solution |Theta|]
A \emph{constraint solution} |Theta| is a pair |(CHR,CnstrAss)|,
where |CHR| is a set of Constraint Handling Rules (defined later) and
|CnstrAss| is a set of |Assume| constraints.
|CHRorig isbydef prenv| denotes the instance and class declarations which induce |CHR|,
\end{Definition}

Constraint satisfaction is defined in terms of entailment:

\begin{Definition}[Constraint Satisfaction |solves|]
Let |Theta| be a constraint solution |(CHR,CnstrAss)|.
A \emph{Prove} constraint is satisfied if the corresponding |varpi| is entailed by |Theta|.
%%[[wrap=code
Theta solves Prove          varpi                                  ^^   isdef     ^^    CHRorig;CnstrVarpi(CnstrAss) entails varpi
Theta solves Assume         varpi                                  ^^   isdef     ^^    Assume varpi insign CnstrAss
Theta solves Reduction      varpi info ^^ {varpi1, ... , varpin}   ^^   isdef     ^^    True
%%]]
An \emph{Assume} is satisfied if the assumed |varpi| is an element of |CnstrAss|.
A \emph{Reduction} is trivially satisfied.
\end{Definition}

\Paragraph{Constraint Handling Rules}

A Constraint Handling Rule (CHR) declaratively specifies how to rewrite a constraint for
a particular problem domain \cite{fruhwirth98theory-chr,fruhwirth03essence-constrprog}.
Each such CHR must be of a specific form:

%%[[wrap=code
H1, ... , Hi <==>  G1, ... , Gj ^^ | ^^ B1, ... , Bk      ^^  (simplification)
H1, ... , Hi  ==>  G1, ... , Gj ^^ | ^^ B1, ... , Bk      ^^  (propagation)

(i > 0, j >= 0, k >= 0)
%%]]

The set of constraints |(H1, ..., Hi)| is the \IxAsDef{head} of a CHR,
the set of conditions |(G1, ..., Gj)| form the \IxAsDef{guard} of a CHR, and the constraints |(B1, ..., Bk)| form
the \IxAsDef{body} of a CHR.

Operationally, CHRs modify a working set of constraints:
a simplification rule replaces the set of constraints matching
the head by the constraints in the body when the conditions in the guard
are satisfiable. A propagation rule adds instead of replaces
the constraints in the body if
the constraints in the head are present and the conditions in the guards
are satisfiable. A propagation rule can be applied infinitely many times,
but we avoid non-termination as a result of this
by applying a propagation rule only once
to every constraint in the constraint set.
Duplicate constraints are considered redundant, that is, we use set semantics for sets of constraints.

CHRs can be given a declarative semantics \cite{fruhwirth98theory-chr,fruhwirth03essence-constrprog}.
A simplification is a logical equivalence if the guards are satisfied:
%%[[wrap=code
forall ^ Vec(x) forall ^ Vec(y)  ((G1 && ... && Gj)
                                 -> (H1 && ... && Hi <--> exists ^ Vec(z) (B1 && ... && Bk)))
%%]]
Similarly, a propagation is an implication if the guards are satisfied:
%%[[wrap=code
forall ^ Vec(x) forall ^ Vec(y)  ((G1 && ... && Gj)
                                 -> (H1 && ... && Hi -> exists ^ Vec(z) (B1 && ... && Bk)))
%%]]
where |Vec(x) = fv ^ ((Vec(G)))|, |Vec(y) = fv ^ ((Vec(H))) \\ Vec(x)| and |Vec(z) = fv ^ ((Vec(B))) \\ (Vec(x) `union` Vec(y))|
are the free variables of the guard, head and body respectively.
Although we omit the quantifiers, rules still should be read as if quantified as above.

We introduce scopes in \secRef{sec-chr-maplocaltochr},
where they are required for the first time.
%%]

%%[toCHRplain
\Paragraph{Simplication and context reduction}

Suppose we have the following class and instance declarations:
%%[[wrap=code
class Eq  a                ^^   ^^     --   (C1)
class Eq  a   => Ord a     ^^   ^^     --   (C2)
class Ord a   => Real a    ^^   ^^     --   (C3)
instance Eq a => Eq [a]    ^^   ^^     --   (I1)
%%]]

These declarations translate to the following set of CHRs,
where |varpi isbydef pi| and |pi| is a class predicate:
%%[[wrap=code
Prove(Eq a)    , Prove(Ord a)    <==> Prove(Ord a)    ^^ ^^ -- (C2)
Prove(Ord a)   , Prove(Real a)   <==> Prove(Real a)   ^^ ^^ -- (C3)
Prove(Eq a)    , Prove(Real a)   <==> Prove(Real a)   ^^ ^^ -- (C23)
Prove(Eq [a])                    <==> Prove(Eq a)     ^^ ^^ -- (I1)
%%]]

A possible derivation using these rules is:

%%[[wrap=code
          ^^  {Prove(Eq [v1])  , Prove(Ord v1), Prove(Real v1)}
deriv(I1) ^^  {Prove(Eq v1)    , Prove(Ord v1), Prove(Real v1)}
deriv(C2) ^^  {Prove(Ord v1)   , Prove(Real v1)}
deriv(C3) ^^  {Prove(Real v1)}
%%]]

All rules but C23 directly correspond to a class or instance declaration.
In order to guarantee confluence \cite{fruhwirth98theory-chr,fruhwirth03essence-constrprog}
it is necessary to explicitly represent the
transitive closure of the class hierarchy by a set of rules.
Were rule C23 is not available,
the following derivation for the same initial constraint set is possible:

%%[[wrap=code
          ^^  {Prove(Eq [v1])  , Prove(Ord v1), Prove(Real v1)}
deriv(C3) ^^  {Prove(Eq [v1])  , Prove(Real v1)}
deriv(I1) ^^  {Prove(Eq v1)    , Prove(Real v1)}
%%]]

This derivation follows a different path of applied CHRs
but does not lead to the same final constraint set:
without rule C23 the CHRs are not confluent
and we cannot conclude with |Prove(Real v1)|.

\Paragraph{Interaction with type inference}
%\Paragraph{|Assume| constraints and type inference}

The constraint set |{Prove(Eq [v1]),| |Prove(Ord v1),| |Prove(Real v1)}|
may have arisen from:

%%[[wrap=code
f (x:xs)  =   xs  ==  []                    --  Prove(Eq [v1])
          &&  x   <   1                     --  Prove(Ord v1)
          &&  const True (toRational x)     --  Prove(Real v1)
%%]]

Constraint solving is done for |f|'s binding group, after all information about |v1| is
reconstructed,
and then leaves us with an unsatisfied |Prove(Real v1)|.
We only can satisfy this constraint
if we have a corresponding assumption |Assume(Real v1)| using the following rule:

%%[[wrap=code
Prove p, Assume p <==> Assume p ^^ ^^ -- (E)
%%]]

An |Assume(Real v1)| can be introduced in two ways:

\begin{itemize}
\item
  The type inferencer decides to generalize over class predicate |Real v1| and constructs the following type for |f|:
%%[[wrap=code
f :: Real a => [a] -> Bool
%%]]
  In this case unresolved |Prove| constraints lead to corresponding |Assume| constraints,
  and constraint solving can proceed with these |Assume| constraints.
\item
  The programmer has provided the type signature:
%%[[wrap=code
f :: Real a => [a] -> Bool
%%]]
  In this case the type signature directly leads to a constraint |Assume(Real c1)| for some fixed type variable |c1|,
  and the body yields |{Prove(Eq [c1]),| |Prove(Ord c1),| |Prove(Real c1)}|.
\end{itemize}

Here we differ from the `standard' CHR \cite{stuckey02theory-overloading} way of dealing with type signatures
by encoding their entailment check as rule E combined with a richer constraint language which includes an |Assume|.
We also expect the type inferencer to be capable of using a type signature in such a way that fixed type variables introduced
by the signature end up in |Prove| constraints via their binding from program variables;
this is usually accomplished by a combination of type inference and type checking
\cite{peytonjones04pract-inf-rank,vytiniotis06boxy-impred,dijkstra05phd}.
Such explicit assumptions will come to good use when dealing with scopes and alternate entailment solutions.

%\Paragraph{|Prove| constraints and type inference}

\Paragraph{Type signatures}

Suppose we have a simpler definition of |f|:

%%[[wrap=code
f (x:xs)  =   xs  ==  []                    --  Prove(Eq [v1])
%%]]

for which we infer:

%%[[wrap=code
f :: Eq a => [a] -> Bool
%%]]

However, providing a type signature |f :: Real a => [a] -> Bool|
may leave us with unresolved constraints, unless we add the class hierarchy
induced rules for |Assume|
constraints  as well.
Otherwise we get stuck at |{Prove(Eq c1),| |Assume(Real c1)}| because there are no rules to simplify to
|{Prove(Eq c1),| |Assume(Eq c1)}|.
Once again,
by adding propagation rules for |Assume| constraints corresponding to the class hierarchy:

%%[[wrap=code
Assume(Ord a)    ==> Assume(Eq a)  ^^ ^^  -- (CA2)
Assume(Real a)   ==> Assume(Ord a) ^^ ^^  -- (CA3)
%%]]

the derivation for |{Prove(Eq c1),| |Assume(Real c1)}| can proceed:

%%[[wrap=code
           ^^   {Prove(Eq c1), Assume(Real c1)}
deriv(CA3) ^^   {Prove(Eq c1), Assume(Real c1), Assume(Ord c1)}
deriv(CA2) ^^   {Prove(Eq c1), Assume(Real c1)
                , Assume(Ord c1), Assume(Eq c1)}
deriv(E)   ^^   {Assume(Real c1), Assume(Ord c1), Assume(Eq c1)}
%%]]

\Paragraph{Overlapping instances: simplification versus propagation rules}

Until now we have used simplification rules for encoding instance declarations: 

%%[[wrap=code
Prove(Eq [a])                    <==> Prove(Eq a)     ^^ ^^ -- (I1)
%%]]

Operationally this means that a CHR solver may replace the prove requirement for |Prove(Eq [a])|
with a prove requirement for |Prove(Eq a)|.
However, in the presence of overlapping instances we loose confluence:

%%[[wrap=code
instance Eq a => Eq [a]    ^^   ^^     --   (I1)
instance Eq [Int]          ^^   ^^     --   (I2)
%%]]

From (I2) we now also have the rule:

%%[[wrap=code
Prove(Eq [Int])                    <==> True     ^^ ^^ -- (I2)
%%]]

Solving |Prove(Eq [Int])| either leads to |Prove(Eq Int)| via (I1) or to |True| via (I2).
A solution to this ambiguity may be to add guards \cite{stuckey02theory-overloading}:

%%[[wrap=code
Prove(Eq [a])                   <==> a /= Int | Prove(Eq a)       ^^ ^^ -- (I1)
Prove(Eq [Int])                 <==> True                         ^^ ^^ -- (I2)
%%]]

However, although this indeed inhibits rule (I1) where appropriate,
it requires all instances to be known, checked for their specificness relative
to each other, and guards to be generated accordingly.
This conflicts with separate compilation and a module structure
-- GHC therefore inhibits context reduction using instances unless enforced by a type signature --
and
it is unclear how it interacts with more complex type-class extensions.
Furthermore, a simplification rule as above enforces a choice between instances;
this conflicts with our intention to make such choices visible,
so we can deal with those choices separately.

For these reasons we will avoid simplification rules and use propagation rules instead.
A direct consequence is that we have confluence because no constraint is ever removed from the working set of a solver,
and every matching propagation rule is used once for matching constraints.

However, the final constraint set yielded by a solver now contains all possible solutions, because we never get rid of
constraints anymore. We have pushed the decision making problem ahead, and this is where our framework for heuristically making
choices comes into play (\secRef{sec-chr-heuristics}).

A more subtle consequence of this design choice is that the interaction with a constraint solver becomes slightly different:
entailment does no longer follow from the absence of |Prove| constraints in the final set of solved constraints,
but non-entailment follows from a |Prove| constraint \emph{not} being propagated from by any rule.
We come back to this later (\secRef{sec-chr-heuristics}).

\Paragraph{Making choice explicit: derivation tracing}

The given rules describe how to solve constraints, but leave no trace of how this is done, do not indicate solution alternatives,
and do not give enough information when proceeding with code generation.
We therefore let each rule also generate a |Reduction| constraint,
thus encoding a derivation trace.
Note that such traces are also generated for derivations which lead to unsatisfiable constraint sets;
choosing between alternate reductions later will prune away such traces, or pick the best of these,
depending on the strategy for making such choices.
Consider again the following instance declarations:

%%[[wrap=code
instance Eq a => Eq [a]    ^^   ^^     --   (I1, dEqList)
instance Eq [Int]          ^^   ^^     --   (I2, dEqListInt)
%%]]

These instances lead to the following propagation rules:

%%[[wrap=code
Prove(Eq [a])
  ==>  Prove(Eq a)                                            ^^ ^^ -- (I1)
  ,    Reduction (Eq[a]) "dEqList" {Eq a}
Prove(Eq [Int])
  ==>  Reduction (Eq [Int]) "dEqListInt" {}                   ^^ ^^ -- (I2)
%%]]

Solving |Prove(Eq [Int])| now results in the following constraint set:

%%[[wrap=code
{  Prove (Eq[Int])
,  Reduction (Eq[Int]) "dEqList" {Eq Int}
,  Prove(Eq Int)
,  Reduction (Eq[Int]) "dEqListInt" {}   }
%%]]

The |info| field of a |Reduction| constraint holds additional (generated) information we need in subsequent
stages.
Here it holds the dictionary name.
Later we introduce a more elaborate |Annotation| datatype for the |info| field of a |Reduction|.

We also need different rules for a class hierarchy.
For example, for the following class:

%%[[wrap=code
class (Eq a, Show a) => Num a
%%]]

we generate the following CHRs, where the |info| field of a |Reduction| now refers to the field of the dictionary
holding the superclass dictionary:

%%[[wrap=code
Assume(Num a)
  ==>  Assume(Eq a)
  ,    Reduction (Eq a)    "eqOfNum"     ^^ {Num a}
  ,    Assume(Show  a)
  ,    Reduction (Show a)  "showOfNum"   ^^ {Num a}
Prove(Eq a), Prove(Num a)
  ==>  Reduction (Eq a)    "eqOfNum"     ^^ {Num a}
Prove(Show a), Prove(Num a)
  ==>  Reduction (Show a)  "showOfNum"   ^^ {Num a}
%%]]

The reduction steps now tell us whether a class predicate |pi| is entailed;
in the above example |Eq Int| is not entailed because there is no |Reduction| constraint for |Eq Int|.
Before proceeding with the construction of a reduction graph to be used in choosing between alternate reduction paths
in \secRef{sec-chr-heuristics},
we first turn our attention to scoped instances and their CHR representation.

%%]

%%[toCHRscoped
Scoped instances allow us to write:

%%[[wrap=code classEq
class Eq a where
  (==) :: a -> a -> Bool
  
instance Eq Int where                                       ^ -- (I1)
  x == y = primEqInt x y

e1 =  3 == 5                                                ^ -- result: False
e2 =  let  instance Eq Int where                            ^ -- (I2)
             x == y = primEqInt  (x `mod` 2)
                                 (y `mod` 2)                ^
      in   3 == 5                                           ^ -- result: True
%%]

A scope |scope| is defined as a sequence of |Int|s,
where longer sequences represent more deeply nested scopes,
and later elements uniquely identify nested scopes within the enclosing scope,
represented by the prefix of such an element:
%%[[wrap=code
type scope = [Int]
%%]]
Identifiers |s, t| are used to denote scopes |scope|.
Scope constants are denoted between |<...>| to avoid confusion with other uses of |[...]|
The common scope of two scopes is defined as their longest common prefix,
which always exists because the global scope always is common:

%%[[wrap=code
commonScope :: scope -> scope -> scope
commonScope (s:ss)  (t:ts)  | s == t     = s : commonScope ss ts
                            | otherwise  = []
commonScope _       _                    = []
%%]]

A scope |s| is visible from a scope |t| if their common scope equals |s|:

%%[[wrap=code
visibleIn :: scope -> scope -> Bool
s `visibleIn` t = s == commonScope s t
%%]]

Both CHRs and constraints reduced by those CHRs must be annotated with scope:
constraints arisen in scope |scope| can only be reduced by instances defined in |scope'|, where |scope'| is visible from |scope|.
We define the scope |scope| of a program location as follows:

\begin{itemize}
\item
  The global scope |scope isbydef ^^ << >>|.
\item
  The body of each |let| introduced binding has scope |scope isbydef scope' ++ [n]|,
  where |n| is a unique |Int| value among all bindings in the surrounding scope |scope'|.
%\item
%  The body of a lambda expression in scope |scope'| for which the type signature (if any) specifies class predicates
%  has scope |scope isbydef scope' ++ [0]|.
\end{itemize}

The scope of both an instance and an induced constraint is defined to be the scope of the program location where
the instance is defined or the constraint arises, respectively.
A class predicate |pi| in a constraint is annotated with this scope |scope|, so |varpi isbydef (pred,scope)|,
alternatively denoted by |predscope|.
When the scope |scope| is omitted from |predscope|, |pred| ranges over any scope.
For instance declarations we need to know their scope,
so |prenv| from now on holds pairs |(instance ^^ Vec(pred) => pred,scope)|.

For example, the global scope in which (I1) is defined is |scope = << >>|, the scope in which (I2) is defined is |scope = <<3>>|,
where the |3| is arbitrary.
The constraint |Prove (Eq Int)| for expression |e1| arises in scope |<< >>|, for expression |e2| it arises in scope |<<3>>|.
For the latter both (I1) and (I2) can be used for context reduction.
This normally implies an error because instances overlap,
but by using scope information we can disambiguate.

The entailment relation is extended (in \figRef{MiscRules.entailscn.all}) with a rule for
making a global scoped predicate locally available.
The rule for instances is restricted to apply to predicates of the same or more local scope only.
The class rule still applies to any predicate since classes are only defined globally.

\rulerCmdUse{MiscRules.entailscn.all}

The scope rule is non-deterministic: it can be applied anywhere and reduce to any outer or equal scope.
In principle, this does not matter because we postpone making choices anyway.
However, in practice we introduce many intermediate reduction steps which clutter the reduction graph.
Therefore we make the rules \IxAsDef{CHR suitable} by modifying the rules such that every rule contributes
a step in the right direction, that is strictly more global scope, fewer predicates to proof, or both:
\begin{itemize}
\item Rules for class and instances are as usual, but preserve scope.
\item Scope reducing rules are for combinations of predicates of which scopes strictly differ,
  and lead to a simplification with a strictly more global scope.
\end{itemize}

In \ruleRef{inst} of \figRef{MiscRules.entailscn.algo}
we already automatically get scope reduction for instances without context.
For instances with context, the scope is propagated to the context.
For scope reductions the \ruleRef{scope} now only reduces two predicates simultaneously which only
differ in their scope.
The \ruleRef{class1} is the same as the previous \ruleRef{class}
but is incomplete on its own because two predicates with different scope in a superclass relationship are
not reduced.
The previous version of \ruleRef{scope} did `spontaneously' reduce predicates to the required scope for \ruleRef{class1},
but now we require additional rules \textRL{class2} and \textRL{class3} to take care of this combination.
The overbar notation in these rules should be read as a rule for each predicate related by the superclass relation.

We have not proven soundness and completeness of the rules in
\figRef{MiscRules.entailscn.algo} relative to \figRef{MiscRules.entailscn.all}.
The intuition is that both sets of rules in \figRef{MiscRules.entailscn.all} independently reduce via instances (and classes) and via scopes.
The rules in \figRef{MiscRules.entailscn.algo} do this in a syntax directed manner by letting the set
of the to be proven predicates determine which rule applies.

\rulerCmdUse{MiscRules.entailscn.algo}

\Paragraph{CHRs for instances}

We change the translation of instances to CHRs accordingly,
for the declaration |instance (pred1, .. , predn) => pred|,
in scope |scope| we get:

%%[[wrap=code
Prove (pred, s)
  ==>  scope `visibleIn` s 
  |    Reduction (pred, s) (ByInstance name scope) ^^ {(pred1, s), .. , (predn, s)}
  ,    Prove (pred1, s), .. , Prove (predn, s)
%%]]

The |Reduction| constraint is annotated with both the name and the scope of the instance;
we come back to |ByInstance| later when this annotation is used to choose between |Reduction| constraints.
For the current example we have:

%%[[wrap=code
Prove (Eq Int, s)
  ==>  << >> `visibleIn` s 
  |    Reduction (Eq Int, s) (ByInstance "I1" << >>) ^^ {}
Prove (Eq Int, s)
  ==>  <<3>> `visibleIn` s 
  |    Reduction (Eq Int, s) (ByInstance "I2" <<3>>) ^^ {}
%%]]

and the following derivation for |Prove (Eq Int, <<3>>)| arising at (e2):

%%[[wrap=code
          ^^  {Prove (Eq Int, <<3>>)}
deriv(I1) ^^  {Prove (Eq Int, <<3>>)
              , Reduction (Eq Int, <<3>>) (ByInstance "I1" << >>) {}}
deriv(I2) ^^  {Prove (Eq Int, <<3>>)
              , Reduction (Eq Int, <<3>>) (ByInstance "I1" << >>) {}
              , Reduction (Eq Int, <<3>>) (ByInstance "I2" <<3>>) {}}
%%]]

where the |Reduction| constraints in the final constraint set correspond to the graph in \figRef{chr-redGraphEqIntTwice}.
We still have overlapping instances, but we are prepared for making the choice.

\FigurePDF{t}{0.55}{redGraphEqIntTwice}{Context reduction for scoped Eq Int}{chr-redGraphEqIntTwice}

\Paragraph{CHRs for classes}

%\FigurePDF{t}{0.5}{redGraphSuperScopeNo}{Missing: scoped superclass reduction}{chr-redGraphSuperScopeNo}

For classes we generate rules for each pair |(pred2, pred3)|, where |pred2| is a (transitive) superclass of |pred3|.
These CHRs correspond to \ruleRef{class2} and \ruleRef{class3}, respectively:

%%[[wrap=code
Prove (pred3, s), Prove (pred2, t)
  ==>   not (s `visibleIn` t)
  |     Prove (pred3, commonScope s t)
  ,     Reduction  (pred3, s) 
                   (ByScope (commonScope s t))
                   {(pred3, commonScope s t)}

Prove (pred3, s), Prove (pred2, t)
  ==>   not (t `visibleIn` s)
  |     Prove (pred2, commonScope s t)
  ,     Reduction  (pred2, t) 
                   (ByScope (commonScope s t))
                   {(pred2, commonScope s t)}
%%]]

\RuleRef{class1} differs from \ruleRef{class} only in the scope, which is irrelevant for classes.
Scope is simply propagated; we therefore omit further discussion.

\Paragraph{CHRs for scoped predicate pairs}

The CHR counterpart of \ruleRef{scope} also is straightforward:

%%[[wrap=code
Prove (p, s), Prove (p, t)
  ==>   t `visibleIn` s, s /= t
  |     Prove (p, t)
  ,     Reduction  (p, s)  (ByScope t) ^^ {(p, t)}
%%]]

\Paragraph{Remaining CHRs}

We also require CHRs dealing with entailment relative to |Assume| constraints.
These CHRs are variants of the CHRs for rules \textRL{class2}, \textRL{class3}, and \textRL{scope},
where the more global |Prove| constraint has been replaced by an |Assume| constraint;
here we have omitted these CHRs, see \blindcite{geest07cnstr-tycls-ext} instead.

%%]

%%[heuristics
The CHR solver leaves us with a final set of constraints, for which:

\begin{itemize}
\item We extract all |Reduction| constraints.
\item From these |Reduction| constraints we construct a reduction graph such as in \figRef{chr-redGraphEqIntTwice},
      and consider all possible alternative reductions.
\item From alternative reductions we choose heuristically.
\item From the chosen reduction we generate evidence, that is, a representation of the code required for constructing dictionaries.
\end{itemize}

We use the following running example, where \figRef{chr-redGraphEqOrdListTup} shows the reduction graph for |f|:

%%[[wrap=code
instance Eq Int                      -- dEqInt  
instance Eq a => Eq [a]              -- dEqL    
instance (Eq a,Eq b) => Eq (a,b)     -- dEqTup  
instance Ord Int                     -- dOrdInt 
instance Ord a => Ord [a]            -- dOrdL   
instance (Ord a,Ord b) => Ord (a,b)  -- dOrdTup 

f :: Ord a => (Int,a) -> [(Int,a)] -> Bool
f x (y:ys) = x == y && x < y && [x] == ys && [y] < ys
%%]]

\FigurePDF{t}{0.5}{redGraphEqOrdListTup}{A reduction graph}{chr-redGraphEqOrdListTup}

We present this sequence of steps in Haskell.
We omit the glue for all code fragments, and only show the essentials;
the implementation is fully described in \blindcite{geest07cnstr-tycls-ext}.

\Paragraph{Constraints}

From the CHR solver we get the final set of constraints, where constraints are represented as:

%%[[wrap=code
data Constraint varpi info
  =  Prove      varpi
  |  Assume     varpi
  |  Reduction  varpi info [varpi]
%%]]

Again, with |varpi isbydef (pred,scope)|.
The |info| parameter is defined to be:

%%[[wrap=code
data Annotation
  =  ByInstance    String pred scope     -- instance name, pred, scope
  |  BySuper       String                -- superclass field name
  |  ProveObl      String                -- evidence name
  |  Assumption    String                -- assumed instance name
  |  ByScope       scope                 -- scope reduction
%%]]

In an |Annotation| we encode all the relevant information required to make choices between reduction alternatives
and to generate evidence,
hence these |Annotation|s are stored along with the edges in the reduction graph constructed below from |Reduction| constraints.
Later we define various orderings on |Annotation|s to be used by heuristics to make a choice between the possible paths.

\Paragraph{Reduction graph}

From these constraints we construct the reduction graph,
for which we use the inductive graph library \cite{erwig01inductive-graph} to encode a graph (Annotated Graph, |AGraph|)
for nodes |a| and edges |b|
with the following interface:

%%[[wrap=code
emptyAGraph :: Ord a => AGraph a b

insertEdge   :: Ord a =>    (a, a, b)    -> AGraph a b -> AGraph a b
insertEdges  :: Ord a => [  (a, a, b)]   -> AGraph a b -> AGraph a b
deleteEdge   :: Ord a =>    (a, a)       -> AGraph a b -> AGraph a b

successors, predecessors :: Ord a => AGraph a b -> a -> [(b, a)]
%%]]

Nodes correspond to predicates |CnstrVarpi(Cnstr)| from constraints |Cnstr|,
and edges are reductions labeled with an |Annotation|.
Predicates |varpi| are wrapped in a |Node| so we can represent conjunction:

%%[[wrap=code
data Node varpi  =  Pred varpi
                 |  And [varpi]

true  ::  Node varpi
true  =   And []
%%]]

Disjunction is encoded by multiple outgoing edges in the graph structure.
From the body of |f| we extract the following constraints: one |Assume| constraint from the type signature with scope |<<5,0>>|,
and four |Prove| constraints.
All constraints are mapped to |Annotation|s holding the program variable by which we can refer to the assumed evidence or
evidence of the proof obligations yet to be proven;
it is the responsibility of the user of this framework to provide this information:

%%[[wrap=code
Prove   (Eq   [(Int,c1)]   ,<<5,0>>)  :->  {ProveObl    "p1"}
Prove   (Eq   (Int,c1)     ,<<5,0>>)  :->  {ProveObl    "p2"}
Prove   (Ord  [(Int,c1)]   ,<<5,0>>)  :->  {ProveObl    "p3"}
Prove   (Ord  (Int,c1)     ,<<5,0>>)  :->  {ProveObl    "p4"}
Assume  (Ord  c1           ,<<5,0>>)  :->  {Assumption  "a1"}
%%]]

Note that each constraint maps to multiple |Annotation|s since a constraint may arise many times.
In our example however we only have one |Annotation| per constraint.

From these constraints, together with the class and instance CHRs,
the CHR solver produces the following |Reduction| constraints which lead to the reduction graph
in \figRef{chr-redGraphEqOrdListTup}.
We show two typical elements of the full set of |Reduction| constraints in their full glory:

%%[[wrap=code
{  Reduction  (Ord  (Int, c1),<<5,0>>)
              (ByInstance  "dOrdTup"  (Ord  (Int, c1))  <<5,0>>  )
              {(Ord Int,<<5,0>>), (Ord c1,<<5,0>>)}
,  Reduction  (Eq   c1,<<5,0>>)
              (BySuper     "eqOfOrd"                             )
              {(Ord c1,<<5,0>>)}
,  ...
}
%%]]

\Paragraph{Reduction alternatives}

From a reduction graph we compute reduction alternatives for each |Prove predscope| proof obligation.
This is a straightforward tree representation of the part of the graph relevant for |predscope|:

%{
%format preds = "preds"
%%[[wrap=code
data Alts  varpi info = Alts  varpi  [Red varpi info]
data Red   varpi info = Red   info   [Alts varpi info]

alternatives :: Ord varpi => Graph varpi info -> varpi -> Alts varpi info
alternatives gr = recOr
  where  recOr   p       = Alts  p  (map  recAnd
                                          (successors gr (Pred p))) 
         recAnd  (i, n)  = Red   i  (map  recOr   (preds n))
         preds  n  =   case n of
                         Pred  q   -> [q]
                         And   qs  -> qs
%%]]
%}

\Paragraph{Choosing heuristically}

From these reduction alternatives we choose one based on a heuristic,
and immediately generate evidence:

%%[[wrap=code
data Evidence  varpi info  =  Build varpi info [Evidence varpi info] 
                           |  Unresolved varpi

unresolved :: Eq p => Evidence p info -> [p]
unresolved (Unresolved p)   = [p]
unresolved (Build _ _ ps)   = nub (concatMap unresolved ps)

type Heuristic varpi info =  [info] -> Alts varpi info
                             -> [(info, Evidence varpi info)]
type SimpleHeuristic varpi info = Alts varpi info -> Evidence varpi info

toHeuristic :: SimpleHeuristic p info -> Heuristic p info
toHeuristic h infos alts = zip infos (repeat (h alts))
%%]]

A |SimpleHeuristic| computes evidence for a single |predscope| from reduction alternatives,
|toHeuristic| lifts this computation to a |Heuristic|,
which binds the list of |Annotation|s bound to |predscope| to a single |Evidence|.

A |Heuristic| is our mechanism for steering the otherwise fixed strategy of choosing between reduction alternatives,
thereby making explicit what usually is implicit.
Although we present this mechanism in the form of hard-coded Haskell functions,
one can easily envision the use of a domain specific language for the construction of heuristics instead.

A heuristic is steered by an ordering on |Annotation|s.
For example, the following ordering prefers instance reductions over superclass reductions,
superclass reductions over assumptions, and so on, like in Haskell98:

%%[[wrap=code
haskell98 :: Annotation -> Annotation -> Ordering
haskell98 (ByInstance    _ _  _)  _                      =  GT
haskell98 _                       (ByInstance   _ _  _)  =  LT
haskell98 (BySuper            _)  _                      =  GT
haskell98 _                       (BySuper           _)  =  LT
haskell98 (Assumption         _)  _                      =  GT
haskell98 _                       (Assumption        _)  =  LT
...

h98Heuristic :: Heuristic varpi Annotation
h98Heuristic = toHeuristic (binChoice haskell98)
%%]]

For an Haskell98 heuristic it is sufficient to pairwise compare the |Annotation|s for reduction alternatives
and make a local choice:

%%[[wrap=code
binChoice :: Eq info =>  (info -> info -> Ordering)
                         -> SimpleHeuristic p info
binChoice order = localChoice (const local)
  where  local []  = []
         local is  = [maximumBy order is]

localChoice :: Eq info =>  (p -> [info] -> [info])
                           -> SimpleHeuristic p info  
localChoice choose (Alts p reds) = 
  let  redinfos  = choose p (map info reds)
  in   case filter ((`elem` redinfos) . info) reds of
         []            -> Unresolved p
         [(Red i rs)]  -> Build p i (map (localChoice choose) rs)
         _             -> error "Alternatives left"
%%]]

Function |binChoice| computes the preferred |Annotation| given an ordering on |Annotation|s;
|localChoice| returns this choice unless there is no choice (unresolved constraint) or there is still ambiguity
amongst reductions.

This is also the point where we get to know which constraints are unresolved;
sooner is not possible because which constraints are unresolved depends on the choices we make between reductions.
From this point onwards we also assume that neither unresolved nor ambiguous reductions occur in
the reduction graph, either because they have been reported as an error, or because they
have been replaced by assumptions.
Ambiguous reductions occur when a heuristic can not make a unique choice,
usually leading to ``overlapping instance'' errors.
The latter is done by type inferencing as part of the generalization step.
As a consequence, these functions have to be used twice, first to detect unresolvedness and ambiguity,
and subsequently to produce the actual evidence.

For the current example (\figRef{chr-redGraphEqOrdListTup}) the Haskell98 heuristic prefers reduction by |dEqL|
for |(Eq [(Int,c1)],<<5,0>>)|, fully ignoring scope information.
A |BySuper| reduction is chosen for |(Eq c1,<<5,0>>)|, for which no |ByInstance| alternative is available.

\Paragraph{GHC heuristic}

GHC \cite{www04ghc} uses a different context reduction strategy in order to support overlapping instances and arbitrary contexts
in type signatures \cite{peytonjones97typecl-explore}.
Haskell98 eagerly reduces context as far as possible, whereas GHC delays context reduction using instances as long as possible.
A predicate is only reduced when it can be resolved locally (tautological predicate) or when forced by a type signature.
GHC first tries to reduce predicates using the following local heuristic:

%%[[wrap=code
ghcBinSolve :: Annotation -> Annotation -> Ordering
ghcBinSolve (Assumption         _)  _                     = GT
ghcBinSolve _                       (Assumption       _)  = LT
ghcBinSolve (BySuper            _)  _                     = GT
ghcBinSolve _                       (BySuper          _)  = LT
ghcBinSolve (ByInstance    _ _  _)  _                     = GT
ghcBinSolve _                       (ByInstance  _ _  _)  = LT
...

ghcSolve :: Eq p => SimpleHeuristic p Annotation
ghcSolve = binChoice ghcBinSolve
%%]]

The most notable difference between the heuristics of Haskell98 and GHC
is the way predicates are reduced using instance declarations:
Haskell98 requires predicates to be reduced first with instance declarations, whereas GHC
reduces predicates only with instance declarations if there is no other
alternative left.
This is possible because GHC allows
arbitrary contexts in type signatures. Were GHC to first reduce using
instances, possibly no assumptions introduced by type
signatures would be found. GHC uses another heuristic when there are still |Unresolved|
nodes in the solution found by the |ghcSolve| heuristic:

%%[[wrap=code
ghcLocalReduce :: a -> [Annotation] -> [Annotation]
ghcLocalReduce _  reds =  let  p (BySuper  _)  = True
                               p _             = False
                          in   filter p reds

ghcReduce :: Eq p => SimpleHeuristic p Annotation
ghcReduce = localChoice ghcLocalReduce
%%]]

This heuristic only reduces a predicate using the class hierarchy.
Context reduction stops the class hierarchy
does not enable reductions, even when there are other alternatives.
We introduce the |try| combinator to combine both heuristics:

%%[[wrap=code
try :: Eq p =>  SimpleHeuristic p info -> SimpleHeuristic p info
                -> SimpleHeuristic p info
try f g a  | null (unresolved e)    = e
           | otherwise              = g a
           where e = f a

ghcHeuristic :: Eq p => Heuristic p Annotation
ghcHeuristic = toHeuristic (try ghcSolve ghcReduce)
%%]]

\Paragraph{Overlapping instance heuristic}

A heuristic that deals with overlapping instances by preferring the instance for a more specific class predicate.
We assume function |specificness| which orders two class predicates accordingly.
We adapt |ghcBinSolve| as an example:

%%[[wrap=code
specificness :: pi -> pi -> Ordering    ^ -- p \texttt{>} q when more specific
specificness p q = ...                  ^ -- error when equal

ghcBinSolve :: Annotation -> Annotation -> Ordering
ghcBinSolve (Assumption         _)  _                     = GT
ghcBinSolve _                       (Assumption       _)  = LT
ghcBinSolve (BySuper            _)  _                     = GT
ghcBinSolve _                       (BySuper          _)  = LT
ghcBinSolve (ByInstance    _ p  _)  (ByInstance  _ q  _)  = cmp
  where cmp = specificness p q
ghcBinSolve (ByInstance    _ _  _)  _                     = GT
ghcBinSolve _                       (ByInstance  _ _  _)  = LT
...
%%]]

\Paragraph{Scoped instance heuristic}

Our last heuristic takes scope into account: instances with more deeply nested scopes are preferred.

%%[[wrap=code
ghcBinSolve (ByInstance    _ _  s)  (ByInstance  _ _  t)  = cmp
  where cmp = length s `compare` length t 
ghcBinSolve (ByInstance    _ _  _)  _                     = GT
ghcBinSolve _                       (ByInstance  _ _  _)  = LT
...
%%]]

With this heuristic we choose instance (I2) for |(Eq Int, <<3>>)| in \figRef{chr-redGraphEqIntTwice}.

%%]

%%[refinements
----------------

Although the rules in \figRef{MiscRules.entailscn.algo} (and omitted rules present in \figRef{MiscRules.entailn.all})
are sufficient for entailment,
they do not provide detailed enough information about when exactly scope related choices are made.
More precisely, the rules do not make explicit when the scope changes take place: use of different scope is hidden inside
the instance rule.
We need this information to be explicit so we can make a choice between 'forgetting scope' and 'using an instance'.
%%]

%%[discussion
\Paragraph{Theoretical aspects}

The contribution of \thispaper\ is a proposal and an implementation, both of practical nature.
Theoretical work has to be done for the following:

\begin{Itemize}
\item
  Proof of soundness and completeness of the rules in \figRef{MiscRules.entailscn.algo}
  relative to \figRef{MiscRules.entailscn.all}.
\item
  Embedding in a type system.
\item
  Formalisation of the heuristics.
\end{Itemize}

We expect the last of these to be the most difficult.

%if False
\Paragraph{Related work}

It appears as if not much work related to scoped instances has been done.
In the discussion of previous work (\secRef{sec-chr-startingpoint}) we observed that named instances
\cite{kahl01named-instance,scheffczyk01mth-namedinst}
are closely related to scoped instances because referring by name to an instance clearly disambiguates between alternative instances.
Although the desirability of scoped instances is noted in literature
\cite{kiselyov04impl-config,shields01first-class-mod},
loss of principal typing and coherence turn out to be major stumbling blocks.
However, we feel that by offering mechanisms to explicitly deal with these issues,
the severity of this is mitigated.
%endif

\Paragraph{Explicitly dealing with otherwise implicit choices}

With our framework we now are able to be explicit in the choices made during context reduction,
and thereby be free from the choices usually made deep inside the bowels of a compiler: context reduction is now programmable.
Different varieties of context reduction \cite{peytonjones97typecl-explore} can be chosen from by means
of compiler options, pragmas, or via a heuristics language and compiler plugins.
We feel that separating proof machinery from solution choice provides a good starting point
for making this part of the compilation process fully steerable by a programmer.

\Paragraph{Backtracking or choosing between reduction alternatives?}

Our CHRs generate a reduction graph which represents reduction alternatives from which we heuristically choose.
Alternatively, a backtracking CHR version \cite{fruhwirth98theory-chr,fruhwirth03essence-constrprog} could be used instead.
Consequently, choices between alternatives then are expressed as part of CHRs.
It is unclear whether implicitly enforcing choices offers enough or better expressability compared to a Haskell program dealing
explicitly with reduction alternatives.

\Paragraph{Improving substitution related extensions}

Extensions like functional dependencies \cite{jones00class-fundep} require improving substitutions for
type variables in class predicates.
However, different reduction alternatives coexist,
likely using different functional dependencies and resulting improving substitutions.
Consequently, such substitutions, which we do not model, need to be carried along with reduction alternatives.


%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

%%[XX
%%]

